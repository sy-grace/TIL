{"cells":[{"cell_type":"markdown","metadata":{"id":"UKjg766IvMdI"},"source":["# 텐서 조작 (1)"]},{"cell_type":"markdown","metadata":{"id":"OXUZV0j3nBJd"},"source":["## 실습 개요\n","\n","1) **실습 목적**\n","\n","\n","이번 실습은 이론으로 배웠던 **PyTorch의 조작법**을 코드를 통해 확인하고 스스로 실행해 볼 수 있도록 구성하였습니다. 여러 가지 조작 **예시**들과 그에 따른 **결과**를 통해 PyTorch의 조작법을 쉽게 익힐 수 있습니다.😊\n","\n","\n","2) **수강 목표**\n","\n","- 텐서를 생성하고 다양한 타입을 텐서로 변환할 수 있다. (<font color=red><b>Generating Tensor</b></font>)\n","- 텐서의 모양을 변경하고 구현할 수 있다. (<font color =red><b>Reshaping Tensor</b></font>)\n","- 텐서를 합치거나 나누거나 할 수 있다. (<font color=red><b>Merging and Spliting Tensor</font></b>)"]},{"cell_type":"markdown","metadata":{"id":"H5CYPnoeDoRu"},"source":["### 실습 목차\n","* 1. 텐서 이해하기\n","  * 1-1. 텐서를 생성하고 텐서로 변환하는 방법을 이해 및 실습\n","  * 1-2. 텐서에서의 indexing 이해 및 실습\n","* 2. 텐서의 모양 바꾸기\n","  * 2-1. 텐서의 shape 을 바꾸는 여러가지 함수 이해 및 실습\n","  * 2-2. 텐서의 차원을 추가하거나 변경하는 방법에 대한 이해 및 실습\n","  * 2-3. 역할이 비슷한 함수들의 차이 이해 및 실습\n","* 3. 텐서 합치기와 나누기\n","  * 3-1. 여러 텐서를 합치는 방법에 대한 이해 및 실습\n","  * 3-2. 하나의 텐서를 여러개로 나누는 방법에 대한 이해 및 실습"]},{"cell_type":"markdown","metadata":{"id":"tMbQ5FwAX2Bl"},"source":["### 환경 설정\n","> PyTorch 불러오기"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"OW0tn1H4WVQA"},"outputs":[],"source":["import torch # PyTorch 불러오기\n","import numpy as np # numpy 불러오기\n","import warnings # 경고 문구 제거\n","warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","metadata":{"id":"siW2vxW_5R8u"},"source":["## 1. 텐서 이해하기\n","\n","```\n","💡 목차 개요 : 텐서의 생성과 텐서로 변환하는 과정을 이해하고, 값을 변환하거나 추출할 수 있는 방법을 알아봅니다.\n","```\n","\n","- 1-1. 텐서를 생성하고 텐서로 변환하는 방법을 이해 및 실습\n","- 1-2. 텐서에서의 indexing 이해 및 실습\n"]},{"cell_type":"markdown","metadata":{"id":"wOhHH9j78vg0"},"source":["### 1-1 텐서를 생성하고 텐서로 변환하는 방법을 이해 및 실습\n","\n","> Random 한 값을 가지는 텐서를 생성하고, list 나 numpy array 같은 다양한 형태의 배열들을 PyTorch 를 이용하여 텐서로 변환하는 과정을 알아봅니다.\n"]},{"cell_type":"markdown","metadata":{"id":"LKm8y6UjTGgY"},"source":["#### 📝 설명 : 텐서의 값을 무작위로 생성하는 방법들\n","* rand :  0과 1 사이의 균일한 분포 (Uniform Distribution) 에서 무작위로 생성된 텐서를 반환\n","\n","📚 참고할만한 자료:\n","* [rand] https://pytorch.org/docs/stable/generated/torch.rand.html"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":659,"status":"ok","timestamp":1689144284201,"user":{"displayName":"Eddie(김윤기)","userId":"11850705511374304262"},"user_tz":-540},"id":"jLRXK4HLrxFA","outputId":"b4963a07-439c-435c-c69e-4fd77d755185"},"outputs":[{"data":{"text/plain":["tensor([[0.7483, 0.9973, 0.6000],\n","        [0.8749, 0.1380, 0.0085]])"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# 0부터 1 사이의 값을 랜덤하게 NxM 텐서로 반환\n","torch.rand(2, 3) # torch.rand(NxM) NxM은 텐서의 크기를 말합니다."]},{"cell_type":"markdown","metadata":{"id":"Q_z19rLVTR2J"},"source":["#### 📝 설명 : Tensor 의 값을 무작위로 생성하는 방법들\n","* randn : 평균이 0이고 표준 편차가 1인 정규 분포(가우시안 분포)에서 무작위로 생성된 텐서를 반환\n","\n","📚 참고할만한 자료:\n","* [randn] https://pytorch.org/docs/stable/generated/torch.randn.html"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":280,"status":"ok","timestamp":1689144320910,"user":{"displayName":"Eddie(김윤기)","userId":"11850705511374304262"},"user_tz":-540},"id":"8ipRPNgTIKB2","outputId":"54d9f7b7-57eb-461d-a5b4-820e6b5c7f3b"},"outputs":[{"data":{"text/plain":["tensor([[ 0.0281, -0.4082,  0.4547],\n","        [-1.5888,  1.0500,  0.2911]])"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# 가우시안 분포에서 렌덤하게 값을 추출 후, NxM 텐서로 반환\n","torch.randn(2, 3) # torch.randn(NxM) NxM은 텐서의 크기를 말합니다."]},{"cell_type":"markdown","metadata":{"id":"wLeDGlVPTdgH"},"source":["#### 📝 설명 : 텐서의 값을 무작위로 생성하는 방법들\n","\n","* randint : 주어진 범위 내에서 정수값을 무작위로 선택하여 텐서를 생성 (단, 최솟값을 포함하고, 최댓값은 포함하지 않음)\n","\n","📚 참고할만한 자료:\n","\n","* [randint] https://pytorch.org/docs/stable/generated/torch.randint.html"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":842,"status":"ok","timestamp":1689144380968,"user":{"displayName":"Eddie(김윤기)","userId":"11850705511374304262"},"user_tz":-540},"id":"olZplQevJFf1","outputId":"56480bfc-290d-41bb-bdba-e5931bf2742b"},"outputs":[{"data":{"text/plain":["tensor([[6, 1, 9, 2, 3],\n","        [8, 4, 3, 7, 5],\n","        [2, 8, 4, 4, 6],\n","        [6, 8, 2, 5, 6],\n","        [2, 9, 6, 6, 6]])"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# 범위 내의 정수를 N x M 텐서로 반환\n","torch.randint(1, 10, (5, 5)) # 생성 가능한 최솟값 : 1, 최댓값 : 9, (5x5) Tensor 크기"]},{"cell_type":"markdown","metadata":{"id":"mwp8WBDQYuSW"},"source":["#### 📝 설명 : 텐서의 값을 지정해서 생성하는 방법들\n","* zeros : 모든 요소가 0인 텐서 반환\n","\n","📚 참고할만한 자료:\n","* [zeros] https://pytorch.org/docs/stable/generated/torch.zeros.html"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":381,"status":"ok","timestamp":1689144401178,"user":{"displayName":"Eddie(김윤기)","userId":"11850705511374304262"},"user_tz":-540},"id":"3YyNbuqYMQ1m","outputId":"5a1d1731-5faf-4ec4-90f1-c3714eece5cf"},"outputs":[{"data":{"text/plain":["tensor([[0., 0., 0.],\n","        [0., 0., 0.],\n","        [0., 0., 0.]])"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["torch.zeros(3, 3) # torch.zeros(*size) 여기서 size 는 \",\"로 구분하며 차원을 여러개로 늘릴 수 있습니다."]},{"cell_type":"markdown","metadata":{"id":"4exBo4-WY3Ed"},"source":["#### 📝 설명 : 텐서의 값을 지정해서 생성하는 방법들\n","* ones : 모든 요소가 1인 텐서 반환\n","\n","📚 참고할만한 자료:\n","* [ones] https://pytorch.org/docs/stable/generated/torch.ones.html"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":417,"status":"ok","timestamp":1689144424393,"user":{"displayName":"Eddie(김윤기)","userId":"11850705511374304262"},"user_tz":-540},"id":"4Q3JI_JYOj7z","outputId":"ef625ddf-c19b-4f04-d4f9-b34ad3186081"},"outputs":[{"data":{"text/plain":["tensor([[[1., 1.],\n","         [1., 1.]],\n","\n","        [[1., 1.],\n","         [1., 1.]]])"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["torch.ones(2, 2, 2) # torch.ones(*size) 여기서 size 는 \",\"로 구분하며 채널을 여러개로 늘릴 수 있습니다."]},{"cell_type":"markdown","metadata":{"id":"ZyaKU86RZANI"},"source":["#### 📝 설명 : 텐서의 값을 지정해서 생성하는 방법들\n","* full: 모든 요소가 지정된 값인 텐서 반환\n","\n","📚 참고할만한 자료:\n","* [full] https://pytorch.org/docs/stable/generated/torch.full.html"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":291,"status":"ok","timestamp":1689144460687,"user":{"displayName":"Eddie(김윤기)","userId":"11850705511374304262"},"user_tz":-540},"id":"uEORgXbCOvdc","outputId":"c8755b6f-d4c3-4de2-d89f-a6cc4d7e9578"},"outputs":[{"data":{"text/plain":["tensor([[5, 5, 5],\n","        [5, 5, 5]])"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["torch.full((2, 3), 5) # torch.full((size),value) => 괄호로 텐서의 크기 (2,3) 를 입력하고, 지정한 값 value (5) 로 모든 요소가 설정됩니다."]},{"cell_type":"markdown","metadata":{"id":"0s5KqAWKZJsz"},"source":["#### 📝 설명 : 텐서의 값을 지정해서 생성하는 방법들\n","* eye : 단위 행렬 반환 (※ 단위 행렬이란? 대각선 요소가 1이고, 나머지 요소가 0인 행렬)\n","\n","📚 참고할만한 자료:\n","* [eye] https://pytorch.org/docs/stable/generated/torch.eye.html"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1689144545526,"user":{"displayName":"Eddie(김윤기)","userId":"11850705511374304262"},"user_tz":-540},"id":"a_mZvxquPF-D","outputId":"5ecd9fef-5dee-480e-b806-a1856ce74188"},"outputs":[{"data":{"text/plain":["tensor([[1., 0., 0.],\n","        [0., 1., 0.],\n","        [0., 0., 1.]])"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["torch.eye(3) # torch.eye(n) (nxn) 크기를 가지는 단위 행렬 반환, 단위행렬 특성 상 정사각행렬 (square matrix)만 가능"]},{"cell_type":"markdown","metadata":{"id":"uGC1NvljZdCW"},"source":["#### 📝 설명 : 다양한 데이터를 텐서 형식으로 변환하기\n","* tensor : 주어진 데이터를 텐서로 변환. 데이터는 list, tuple, numpy array 등의 형태일 수 있음.\n","\n","📚 참고할만한 자료:\n","* [tensor] https://pytorch.org/docs/stable/generated/torch.tensor.html"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":285,"status":"ok","timestamp":1689144637195,"user":{"displayName":"Eddie(김윤기)","userId":"11850705511374304262"},"user_tz":-540},"id":"Ytl5SeTnVdV9","outputId":"93dddc3f-483f-4ff3-80b6-3ed31cd1e26d"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[ 1,  2,  3,  4,  5],\n","        [ 6,  7,  8,  9, 10]])\n","\n","\n","tensor([1, 2, 3])\n","\n","\n","tensor([[[ 1,  2,  3],\n","         [ 4,  5,  6]],\n","\n","        [[ 7,  8,  9],\n","         [10, 11, 12]]])\n"]}],"source":["# list, tuple, numpy array를 텐서로 바꾸기\n","ls = [[1, 2, 3, 4, 5],[6, 7, 8, 9, 10]] # sample list 생성\n","tup = tuple([1, 2, 3]) # sample tuple 생성\n","arr = np.array([[[1, 2, 3],[4, 5, 6]],[[7, 8, 9],[10, 11, 12]]]) # sample numpy array 생성\n","\n","print(torch.tensor(ls))\n","print('\\n')\n","print(torch.tensor(tup))\n","print('\\n')\n","print(torch.tensor(arr))"]},{"cell_type":"markdown","metadata":{"id":"y7p276DmZlZ4"},"source":["#### 📝 설명 : 다양한 형태를 텐서 형식으로 변환하기\n","* from_numpy : numpy array 를 텐서로 변환\n","\n","📚 참고할만한 자료:\n","* [from_numpy] https://pytorch.org/docs/stable/generated/torch.from_numpy.html"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":270,"status":"ok","timestamp":1689144667382,"user":{"displayName":"Eddie(김윤기)","userId":"11850705511374304262"},"user_tz":-540},"id":"0MUst73hXFWO","outputId":"361278e5-c1b2-4b2e-948a-4959379da438"},"outputs":[{"data":{"text/plain":["tensor([[[ 1,  2,  3],\n","         [ 4,  5,  6]],\n","\n","        [[ 7,  8,  9],\n","         [10, 11, 12]]])"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["torch.from_numpy(arr) # array 를 tensor로 바꾸기 (2)"]},{"cell_type":"markdown","metadata":{"id":"GWVtMesIZuo2"},"source":["#### 📝 설명: 다양한 형식의 텐서 변환\n","* as_tensor: 변환 전 데이터와의 메모리 공유(memory sharing)를 사용하므로, 변환 전 데이터 변경 시 변환되어 있는 텐서에도 반영됨\n","\n","📚 참고할만한 자료:\n","* [as_tensor] https://pytorch.org/docs/stable/generated/torch.as_tensor.html"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":276,"status":"ok","timestamp":1689144732202,"user":{"displayName":"Eddie(김윤기)","userId":"11850705511374304262"},"user_tz":-540},"id":"FUGBYEToXYG6","outputId":"e078826b-c21e-43e8-bae1-6824863e2dd0"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.tensor\n","tensor([1, 2, 3, 4, 5])\n","----------------------------------------------------------------------\n","torch.as_tensor\n","tensor([10,  2,  3,  4,  5])\n"]}],"source":["# torch.tensor 와 torch.as_tensor 의 차이점 알아보기\n","print(\"torch.tensor\")\n","data1 = np.array([1, 2, 3, 4, 5]) # 샘플 데이터 리스트 생성\n","tensor1 = torch.tensor(data1) # memory 공유 X\n","data1[0] = 10  # 원본 데이터 변경\n","print(tensor1)  # 원본 데이터의 값 변경에 영향을 받지 않음\n","\n","print('-------'*10)\n","\n","print(\"torch.as_tensor\")\n","data2 = np.array([1, 2, 3, 4, 5])\n","tensor2 = torch.as_tensor(data2) # memory 공유 O\n","data2[0] = 10  # 원본 데이터 변경\n","print(tensor2)  # 원본 데이터의 값 변경에 영향을 받음"]},{"cell_type":"markdown","metadata":{"id":"wL2tc5hfZ3Kt"},"source":["#### 📝 설명 : 다양한 형식의 텐서 변환\n","* Tensor : float32 type으로 텐서 변환\n","\n","📚 참고할만한 자료:\n","* [Tensor] https://pytorch.org/docs/stable/tensors.html"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1,"status":"ok","timestamp":1689144895244,"user":{"displayName":"Eddie(김윤기)","userId":"11850705511374304262"},"user_tz":-540},"id":"nSDhxbyfZhP1","outputId":"5121af3a-5abe-4d33-b7f7-353d109fe27b"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.tensor\n","Output: tensor([1, 2, 3, 4, 5])\n","Type torch.int64\n","---------------------\n","torch.Tensor\n","Output: tensor([1., 2., 3., 4., 5.])\n","Type torch.float32\n"]}],"source":["data = [1, 2, 3, 4, 5]\n","tensor1 = torch.tensor(data) # list 에서 Tensor 변환\n","print(\"torch.tensor\")\n","print(\"Output:\", tensor1)\n","print(\"Type\", tensor1.dtype) # dtype : Tensor 안의 원소들의 자료형, torch.tensor 는 원본의 데이터 타입을 그대로 따라감\n","\n","print('-------'*3)\n","\n","tensor2 = torch.Tensor(data) # list 에서 Tensor 변환\n","print(\"torch.Tensor\")\n","print(\"Output:\", tensor2)\n","print(\"Type\", tensor2.dtype) # torch.tensor 는 float32 타입으로 Tensor 변환"]},{"cell_type":"markdown","metadata":{"id":"7ss9HhzieBDH"},"source":["### 1-2 텐서에서의 Indexing 을 이해 및 실습\n","\n","> Indexing 개념과 Indexing 을 통해 값을 변경하는 방법에 대해 이해하고 실습합니다."]},{"cell_type":"markdown","metadata":{"id":"dYvdKSEBgjkc"},"source":["#### 📝 설명 : Indexing 이란?\n","Indexing 은 텐서 내의 특정 **요소**를 index를 통해 접근할 수 있는 방법을 의미합니다.\n","* Indexing 기본 : **대괄호(\"[ ]\")**를 통해 이뤄지며, **\":\"** 는 특정 범위의 접근을 의미합니다.\n","\n","📚 참고할만한 자료:\n","* [Tensor indexing] : https://pytorch.org/cppdocs/notes/tensor_indexing.html"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1689144993162,"user":{"displayName":"Eddie(김윤기)","userId":"11850705511374304262"},"user_tz":-540},"id":"EXYM5UoniFg_","outputId":"2fcedbb4-e512-4dfb-ad2b-491bd42eb691"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor(0)\n","tensor(5)\n","tensor(9)\n"]}],"source":["# 1차원 텐서에서 Indexing 하기\n","tmp_1dim = torch.tensor([i for i in range(10)]) # 0부터 9 까지의 값을 가지는 1차원 텐서 생성\n","\n","print(tmp_1dim[0]) # 첫번째 원소 값 추출\n","print(tmp_1dim[5]) # 6번째 원소 값 추출\n","print(tmp_1dim[-1]) # -1 번째 원소 값 (뒤에서 첫번째) 추출"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":288,"status":"ok","timestamp":1689145185788,"user":{"displayName":"Eddie(김윤기)","userId":"11850705511374304262"},"user_tz":-540},"id":"VrBG4imc5TsZ","outputId":"8f296a04-7b60-4078-b3fb-f4818ff22ce9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape :  torch.Size([4, 3, 2])\n","tensor([[[-0.0936,  0.4149],\n","         [ 1.6445,  2.0879],\n","         [ 0.6450,  0.3993]],\n","\n","        [[-0.9695, -0.1274],\n","         [ 0.2981,  0.6424],\n","         [-1.4137,  0.5107]],\n","\n","        [[ 0.1257, -0.9870],\n","         [ 0.4973,  0.9414],\n","         [ 0.8025,  0.2517]],\n","\n","        [[-0.6265,  0.4746],\n","         [-0.8455,  4.1730],\n","         [ 0.7171,  0.8337]]])\n","--------------------------------------------------------\n","torch.Size([4, 3])\n","tensor([[-0.0936,  1.6445,  0.6450],\n","        [-0.9695,  0.2981, -1.4137],\n","        [ 0.1257,  0.4973,  0.8025],\n","        [-0.6265, -0.8455,  0.7171]])\n","\n","\n","torch.Size([3])\n","tensor([0.4149, 2.0879, 0.3993])\n"]}],"source":["# 3차원 텐서에서 Indexing 하기\n","tmp_3dim = torch.randn(4, 3, 2) # 4채널, 3행, 2열\n","print(\"Shape : \", tmp_3dim.shape)\n","print(tmp_3dim)\n","\n","print('-------'*8)\n","\n","print(tmp_3dim[:,:,0].shape)\n","print(tmp_3dim[:,:,0]) # 전체 채널과 전체 행에서 0번째 열만 추출\n","\n","print('\\n') # 줄 띄움\n","\n","print(tmp_3dim[0,:,1].shape)\n","print(tmp_3dim[0,:,1])  # 0번째 채널의 전체 행에서 1번째 열만 추출"]},{"cell_type":"markdown","metadata":{"id":"Tw7YD1ElhaL0"},"source":["#### 📝 설명 : Indexing 이란?\n","* index_select : 선택한 차원에서 인덱스에 해당하는 요소만 추출하는 함수\n","\n","📚 참고할만한 자료:\n","* [index_select] : https://pytorch.org/docs/stable/generated/torch.index_select.html"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1,"status":"ok","timestamp":1689145264268,"user":{"displayName":"Eddie(김윤기)","userId":"11850705511374304262"},"user_tz":-540},"id":"m2Rmp3wpAXRk","outputId":"2cf5e5a0-7452-40e9-ab3b-8846bd1af114"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n","        [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]])\n","\n","\n"]},{"data":{"text/plain":["tensor([[ 0,  2],\n","        [10, 12]])"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["# index_select\n","tmp_2dim = torch.tensor([[i for i in range(10)],[i for i in range(10, 20)]])\n","print(tmp_2dim)\n","\n","print('\\n')\n","\n","my_index = torch.tensor([0, 2]) # 선택하고자 하는 index 는 텐서 형태이어야 함.\n","torch.index_select(tmp_2dim, dim=1, index=my_index) # 열을 기준으로 0열과 2열을 추출"]},{"cell_type":"markdown","metadata":{"id":"4oydX5fshNjz"},"source":["#### 📝 설명 : Indexing 이란?\n","* Masking 을 이용한 Indexing : 조건에 따른 텐서의 요소를 사용하기 위한 방법으로 조건에 맞는 요소들만 반환하는 방법입니다."]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1,"status":"ok","timestamp":1689145330029,"user":{"displayName":"Eddie(김윤기)","userId":"11850705511374304262"},"user_tz":-540},"id":"uBhzYlSt8M5J","outputId":"7216f7f6-a400-4b95-d83c-77dc2e94547e"},"outputs":[{"data":{"text/plain":["tensor([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["# mask 를 이용한 텐서 Indexing (조건에 맞는 값만 추출)\n","mask = tmp_2dim >= 5 # 5보다 큰 텐서만 추출\n","tmp_2dim[mask] # 1차원 Tensor 로 반환"]},{"cell_type":"markdown","metadata":{"id":"lPHHskochuNC"},"source":["#### 📝 설명 : Indexing 이란?\n","* masked_select : 주어진 mask에 해당하는 요소들을 추출하여 1차원으로 펼친 새로운 텐서를 반환하는 함수\n","\n","📚 참고할만한 자료:\n","* [masked_select] : https://pytorch.org/docs/stable/generated/torch.masked_select.html"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":282,"status":"ok","timestamp":1689145356311,"user":{"displayName":"Eddie(김윤기)","userId":"11850705511374304262"},"user_tz":-540},"id":"SOHBPOy9BubK","outputId":"38359d00-6b4a-4511-f34b-06cf68be4df2"},"outputs":[{"data":{"text/plain":["tensor([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["torch.masked_select(tmp_2dim, mask = mask) # tmp_2dim[tmp_2dim >= 5] 와 동일"]},{"cell_type":"markdown","metadata":{"id":"zA_afHzNhx7D"},"source":["#### 📝 설명 : Indexing 이란?\n","* take : 주어진 인덱스를 사용하여 텐서에서 요소를 선택하는 함수. 인덱스 번호는 텐서를 1차원으로 늘려졌을 때 기준으로 접근해야합니다.\n","\n","📚 참고할만한 자료:\n","* [take] : https://pytorch.org/docs/stable/generated/torch.take.html"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":769,"status":"ok","timestamp":1689145434775,"user":{"displayName":"Eddie(김윤기)","userId":"11850705511374304262"},"user_tz":-540},"id":"8v-7FODdCRb2","outputId":"26d51da6-00cf-4041-d4e8-a8924f488499"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n","        [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]])\n","\n","\n"]},{"data":{"text/plain":["tensor([ 0, 15])"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["tmp_2dim = torch.tensor([[i for i in range(10)], [i for i in range(10, 20)]])\n","print(tmp_2dim)\n","\n","print('\\n')\n","\n","my_index = torch.tensor([0, 15])\n","torch.take(tmp_2dim, index = my_index) # Tensor가 1차원으로 늘려졌을 때 기준으로 index 번호로 접근"]},{"cell_type":"markdown","metadata":{"id":"bnXjy1yhh1AK"},"source":["#### 📝 설명 : Indexing 이란?\n","* gather : 주어진 차원에서 인덱스에 해당하는 요소들을 선택하여 새로운 텐서를 반환\n","\n","📚 참고할만한 자료:\n","* [gather] : https://pytorch.org/docs/stable/generated/torch.gather.html"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":279,"status":"ok","timestamp":1689145674626,"user":{"displayName":"Eddie(김윤기)","userId":"11850705511374304262"},"user_tz":-540},"id":"f9DRQiZ7UzvF","outputId":"46fafa51-e723-4c71-b901-602889bc5f56"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n","        [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]])\n","\n","\n","tensor([[0, 1],\n","        [9, 8]])\n","\n","\n"]},{"data":{"text/plain":["tensor([[ 0,  1],\n","        [19, 18]])"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["tmp_2dim = torch.tensor([[i for i in range(10)],[i for i in range(10,20)]])\n","print(tmp_2dim)\n","\n","print('\\n')\n","\n","recon_index =  torch.tensor([[0 ,1],[9, 8]]) # 0번째 값, 1번 째 값을 0번째 행으로 설정하고, 9번째 값, 8번째 값을 1번째 행으로 설정한다.\n","dim = 1 # 열 기준\n","print(recon_index)\n","print('\\n')\n","\n","torch.gather(tmp_2dim, dim = 1, index = recon_index) # dim =1 이므로 열 기준, 0행 0열, 0행 1열 선택, 1행 9열, 1행 8열"]},{"cell_type":"markdown","metadata":{"id":"vRtanbVaT39w"},"source":["## 2. 텐서의 모양 바꾸기\n","\n","```\n","💡 목차 개요 : 텐서의 모양을 바꾸는 방법에 대해 실습을 통해 이해하고, 비슷한 역할을 하는 함수들의 각 차이점에 대해서 알아봅니다.\n","```\n","\n","- 2-1. 텐서의 shape 을 바꾸는 여러가지 함수 이해 및 실습\n","- 2-2. 텐서의 차원을 추가하거나 변경하는 방법에 대한 이해 및 실습\n","- 2-3. 역할이 비슷한 함수들의 차이 이해 및 실습"]},{"cell_type":"markdown","metadata":{"id":"Ypym_EzHcHsm"},"source":["### 2-1 텐서의 shape을 바꾸는 여러가지 함수 이해 및 실습\n","> 텐서의 모양을 자유자재로 바꾸는 방법에 대해 알아보고 실습합니다.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"pL5epVK-i0Dm"},"source":["#### 📝 설명 : 텐서의 shape 변경\n","텐서에 대한 모양을 변경하기 위해 명심해야 할 점은 텐서의 크기 (요소의 개수)는 유지되어야 한다는 점입니다.\n","* size : 텐서의 모양을 확인합니다.\n","\n","📚 참고할만한 자료:\n","* [size] : https://pytorch.org/docs/stable/generated/torch.Tensor.size.html"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":313,"status":"ok","timestamp":1689145794563,"user":{"displayName":"Eddie(김윤기)","userId":"11850705511374304262"},"user_tz":-540},"id":"ipwFOrsidAE7","outputId":"b99d7dc0-4160-4c47-e5e1-e1c607a5bce4"},"outputs":[{"data":{"text/plain":["torch.Size([2, 3, 5])"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["a = torch.randn(2, 3, 5) # random 한 값을 가진 (2,3,5) 텐서 생성\n","a.size() # 차원 크기 확인"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":291,"status":"ok","timestamp":1689145796827,"user":{"displayName":"Eddie(김윤기)","userId":"11850705511374304262"},"user_tz":-540},"id":"8Bx4agDadDYD","outputId":"d45dff02-a683-4e29-dc35-f3bdd169984b"},"outputs":[{"data":{"text/plain":["torch.Size([2, 3, 5])"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["a.shape # a.size() 와 동일"]},{"cell_type":"markdown","metadata":{"id":"LUibyB1ki9fy"},"source":["#### 📝 설명 : 텐서의 shape 변경\n","* reshape : 텐서의 모양을 변경합니다. 메모리를 공유하지 않습니다.\n","\n","📚 참고할만한 자료:\n","* [reshape] : https://pytorch.org/docs/stable/generated/torch.reshape.html"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":302,"status":"ok","timestamp":1689145937577,"user":{"displayName":"Eddie(김윤기)","userId":"11850705511374304262"},"user_tz":-540},"id":"KM-sMX3Ug0WP","outputId":"64e5577e-593c-4ee3-8a80-859be8cca5b9"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[[ 1.5784, -0.1833, -0.7277, -1.2244,  0.1583],\n","         [-0.0312, -1.0573, -0.5420, -2.8822,  1.4488],\n","         [-0.7339, -0.0901,  0.8138,  2.1425,  0.2194]],\n","\n","        [[ 1.4539,  0.2043, -0.7986, -0.5098,  0.3936],\n","         [-0.5497, -0.3626,  1.4789,  0.1768, -0.0831],\n","         [-0.4291,  1.1139, -1.4234,  0.4544,  0.0708]]])\n","Shape :  torch.Size([2, 3, 5])\n","\n","\n","tensor([[ 1.5784, -0.1833, -0.7277, -1.2244,  0.1583, -0.0312],\n","        [-1.0573, -0.5420, -2.8822,  1.4488, -0.7339, -0.0901],\n","        [ 0.8138,  2.1425,  0.2194,  1.4539,  0.2043, -0.7986],\n","        [-0.5098,  0.3936, -0.5497, -0.3626,  1.4789,  0.1768],\n","        [-0.0831, -0.4291,  1.1139, -1.4234,  0.4544,  0.0708]])\n","Shape :  torch.Size([5, 6])\n"]}],"source":["# 모양 변경\n","a = torch.randn(2, 3, 5) # (2,3,5) 크기를 가지는 텐서 생성\n","print(a)\n","print(\"Shape : \", a.size()) # 텐서 모양 반환\n","print('\\n')\n","\n","reshape_a = a.reshape(5, 6) # 3차원 텐서를 2차원 텐서로 크기 변경 (2,3,5) -> (5,6)\n","print(reshape_a)\n","print(\"Shape : \", reshape_a.size()) # 변경한 텐서 모양 반환"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":297,"status":"ok","timestamp":1689145995242,"user":{"displayName":"Eddie(김윤기)","userId":"11850705511374304262"},"user_tz":-540},"id":"M36tGjarh9I7","outputId":"ca879151-d76c-448e-b727-d1be9105ded7"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([3, 10])\n"]}],"source":["# -1 로 모양 자동 설정\n","reshape_auto_a = a.reshape(3, -1) # (2,3,5) 크기를 가지는 Tensor를 (3,n)의 모양으로 변경, \"-1\" 로 크기 자동 계산\n","print(reshape_auto_a.size()) # 2x3x5 = 3 x n 의 방정식을 푸는 문제로 n 이 자동설정"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":174},"executionInfo":{"elapsed":274,"status":"error","timestamp":1689146014861,"user":{"displayName":"Eddie(김윤기)","userId":"11850705511374304262"},"user_tz":-540},"id":"VSviAQIbic9h","outputId":"fbcb9323-6555-40f5-90c6-02ef7eacea74"},"outputs":[{"ename":"RuntimeError","evalue":"shape '[7, -1]' is invalid for input of size 30","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#  2x3x5 = 3 x n 의 방정식의 해가 정수가 아니면 오류 발생\u001b[39;00m\n","\u001b[0;31mRuntimeError\u001b[0m: shape '[7, -1]' is invalid for input of size 30"]}],"source":["a.reshape(7, -1) #  2x3x5 = 3 x n 의 방정식의 해가 정수가 아니면 오류 발생"]},{"cell_type":"markdown","metadata":{"id":"FpQFHxrIjJVe"},"source":["#### 📝 설명 : 텐서의 shape 변경\n","* view : 텐서의 모양을 변경합니다.\n","\n","📚 참고할만한 자료:\n","* [view] : https://pytorch.org/docs/stable/generated/torch.Tensor.view.html"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":308,"status":"ok","timestamp":1689146029645,"user":{"displayName":"Eddie(김윤기)","userId":"11850705511374304262"},"user_tz":-540},"id":"rbmti7R6pvxy","outputId":"47314b4b-8417-4424-dae5-41684bfa66a3"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[[ 1.5784, -0.1833, -0.7277, -1.2244,  0.1583],\n","         [-0.0312, -1.0573, -0.5420, -2.8822,  1.4488],\n","         [-0.7339, -0.0901,  0.8138,  2.1425,  0.2194]],\n","\n","        [[ 1.4539,  0.2043, -0.7986, -0.5098,  0.3936],\n","         [-0.5497, -0.3626,  1.4789,  0.1768, -0.0831],\n","         [-0.4291,  1.1139, -1.4234,  0.4544,  0.0708]]])\n","Shape :  torch.Size([2, 3, 5])\n","\n","\n","tensor([[ 1.5784, -0.1833, -0.7277, -1.2244,  0.1583, -0.0312],\n","        [-1.0573, -0.5420, -2.8822,  1.4488, -0.7339, -0.0901],\n","        [ 0.8138,  2.1425,  0.2194,  1.4539,  0.2043, -0.7986],\n","        [-0.5098,  0.3936, -0.5497, -0.3626,  1.4789,  0.1768],\n","        [-0.0831, -0.4291,  1.1139, -1.4234,  0.4544,  0.0708]])\n","Shape :  torch.Size([5, 6])\n"]}],"source":["print(a)\n","print(\"Shape : \", a.size()) # 텐서 모양 반환\n","print('\\n')\n","\n","view_a = a.view(5, 6) # reshape 과 동일하게 (2,3,5) 크기를 (5,6) 크기로 변경\n","print(view_a)\n","print(\"Shape : \", view_a.size())"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":277,"status":"ok","timestamp":1689146041894,"user":{"displayName":"Eddie(김윤기)","userId":"11850705511374304262"},"user_tz":-540},"id":"QbPBudrtqnqe","outputId":"46681482-c252-4c19-d567-7fa8351b30b0"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([3, 10])\n"]}],"source":["view_auto_a = a.view(3, -1) # reshape 과 동일하게 (3,n)의 모양으로 변경. \"-1\" 로 크기 자동 계산\n","print(view_auto_a.size())"]},{"cell_type":"markdown","metadata":{"id":"KpfbpFqyjio4"},"source":["#### 📝 설명 : 텐서의 shape 변경\n","* transpose : 텐서의 차원을 전치합니다.\n","\n","📚 참고할만한 자료:\n","* [transpose] : https://pytorch.org/docs/stable/generated/torch.transpose.html"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":311,"status":"ok","timestamp":1689146162154,"user":{"displayName":"Eddie(김윤기)","userId":"11850705511374304262"},"user_tz":-540},"id":"fP86P3hdi2S3","outputId":"4c53301f-6f53-457f-d197-10c2f79f5dfb"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[[8, 2, 3, 7, 1],\n","         [5, 1, 9, 3, 1]],\n","\n","        [[3, 5, 6, 1, 8],\n","         [9, 1, 8, 2, 2]],\n","\n","        [[1, 2, 1, 2, 4],\n","         [3, 2, 8, 4, 6]]])\n","Shape :  torch.Size([3, 2, 5])\n","\n","\n","tensor([[[8, 5],\n","         [2, 1],\n","         [3, 9],\n","         [7, 3],\n","         [1, 1]],\n","\n","        [[3, 9],\n","         [5, 1],\n","         [6, 8],\n","         [1, 2],\n","         [8, 2]],\n","\n","        [[1, 3],\n","         [2, 2],\n","         [1, 8],\n","         [2, 4],\n","         [4, 6]]])\n","Shape :  torch.Size([3, 5, 2])\n"]}],"source":["tensor_a = torch.randint(1, 10, (3, 2, 5)) # 1 ~ 9의 값을 가지는 (3,2,5) 사이즈의 Tensor 생성\n","print(tensor_a)\n","print(\"Shape : \", tensor_a.size())\n","print('\\n')\n","\n","# (3,2,5) 를 (2,3,5) 의 크기로 변경\n","trans_a = tensor_a.transpose(1, 2) # 행과 열을 서로 전치, 서로 전치할 차원 2개를 지정\n","print(trans_a)\n","print(\"Shape : \", trans_a.size())"]},{"cell_type":"markdown","metadata":{"id":"6_R9R2Spjeon"},"source":["#### 📝 설명 : 텐서의 shape 변경\n","* permute : 텐서 차원의 순서를 재배열합니다.\n","\n","📚 참고할만한 자료:\n","* [permute] : https://pytorch.org/docs/stable/generated/torch.permute.html"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1689146165226,"user":{"displayName":"Eddie(김윤기)","userId":"11850705511374304262"},"user_tz":-540},"id":"h7Z_fH0oo8Ij","outputId":"3174ec17-cf57-4e34-b1ae-8b53b801dbec"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[[8, 2, 3, 7, 1],\n","         [5, 1, 9, 3, 1]],\n","\n","        [[3, 5, 6, 1, 8],\n","         [9, 1, 8, 2, 2]],\n","\n","        [[1, 2, 1, 2, 4],\n","         [3, 2, 8, 4, 6]]])\n","Shape :  torch.Size([3, 2, 5])\n","\n","\n","tensor([[[8, 5],\n","         [2, 1],\n","         [3, 9],\n","         [7, 3],\n","         [1, 1]],\n","\n","        [[3, 9],\n","         [5, 1],\n","         [6, 8],\n","         [1, 2],\n","         [8, 2]],\n","\n","        [[1, 3],\n","         [2, 2],\n","         [1, 8],\n","         [2, 4],\n","         [4, 6]]])\n","Shape :  torch.Size([3, 5, 2])\n"]}],"source":["print(tensor_a)\n","print(\"Shape : \", tensor_a.size())\n","print('\\n')\n","\n","permute_a = tensor_a.permute(0, 2, 1) # (3,2,5)의 모양을 (3,5,2)의 모양으로 변경\n","print(permute_a)\n","print(\"Shape : \", permute_a.size())"]},{"cell_type":"markdown","metadata":{"id":"O0zh9ojKkjbQ"},"source":["### 2-2 텐서의 차원을 추가하거나 변경하는 방법에 대한 이해 및 실습\n","> 텐서의 차원 변경 방식에 대한 이해와 활용을 할 수 있습니다."]},{"cell_type":"markdown","metadata":{"id":"EOiKDQoAp2XW"},"source":["#### 📝 설명 : 텐서의 차원을 추가하거나 변경하는 방법에 대한 이해 및 실습\n","* unsqueeze : 텐서에 특정 차원에 크기가 1인 차원을 추가합니다.\n","\n","📚 참고할만한 자료:\n","* [unsqueeze] : https://pytorch.org/docs/stable/generated/torch.unsqueeze.html"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":284,"status":"ok","timestamp":1689146234629,"user":{"displayName":"Eddie(김윤기)","userId":"11850705511374304262"},"user_tz":-540},"id":"QpUG5J0Hs3GK","outputId":"3c9ff20a-5f7a-4ff5-d167-b9c072cc2bcb"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[0, 1],\n","        [2, 3],\n","        [4, 5],\n","        [6, 7],\n","        [8, 9]])\n","Shape :  torch.Size([5, 2])\n","\n","\n","tensor([[[0, 1],\n","         [2, 3],\n","         [4, 5],\n","         [6, 7],\n","         [8, 9]]])\n","Shape :  torch.Size([1, 5, 2])\n"]}],"source":["tensor_a = torch.tensor([i for i in range(10)]).reshape(5, 2) # 0부터 9까지의 숫자들을 (5,2) 크기로 변경\n","print(tensor_a)\n","print('Shape : ', tensor_a.size())\n","print('\\n')\n","\n","unsqu_a = tensor_a.unsqueeze(0) # 0번째 차원 하나 추가 (5,2) => (1,5,2)\n","print(unsqu_a)\n","print('Shape : ', unsqu_a.size())"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":275,"status":"ok","timestamp":1689146268849,"user":{"displayName":"Eddie(김윤기)","userId":"11850705511374304262"},"user_tz":-540},"id":"dbR8cf0Luwnq","outputId":"c2d4adcf-94b5-488f-d815-89e3892806ec"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[[0],\n","         [1]],\n","\n","        [[2],\n","         [3]],\n","\n","        [[4],\n","         [5]],\n","\n","        [[6],\n","         [7]],\n","\n","        [[8],\n","         [9]]])\n","Shape :  torch.Size([5, 2, 1])\n"]}],"source":["unsqu_a2 = tensor_a.unsqueeze(-1) # 마지막번째에 차원 하나 추가 (5,2) => (5,2,1)\n","print(unsqu_a2)\n","print('Shape : ', unsqu_a2.size())"]},{"cell_type":"markdown","metadata":{"id":"-2uRteAxkxWf"},"source":["#### 📝 설명 : 텐서의 차원을 추가하거나 변경하는 방법에 대한 이해 및 실습\n","* squeeze : 텐서에 차원의 크기가 1인 차원을 제거합니다.\n","\n","📚 참고할만한 자료:\n","* [squeeze] : https://pytorch.org/docs/stable/generated/torch.squeeze.html"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1688752218232,"user":{"displayName":"JaeHyun Lee","userId":"13762872260843906568"},"user_tz":-540},"id":"kPJxopmYBxuh","outputId":"51191f9a-82b3-4ab5-a3a7-a16f94ea4000"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[[0, 1],\n","         [2, 3],\n","         [4, 5],\n","         [6, 7],\n","         [8, 9]]])\n","Shape :  torch.Size([1, 5, 2])\n","\n","\n","tensor([[0, 1],\n","        [2, 3],\n","        [4, 5],\n","        [6, 7],\n","        [8, 9]])\n","Shape :  torch.Size([5, 2])\n"]}],"source":["print(unsqu_a)\n","print(\"Shape : \", unsqu_a.size())\n","print('\\n')\n","\n","squ = unsqu_a.squeeze() # 차원이 1인 차원을 제거\n","print(squ)\n","print(\"Shape : \", squ.size())"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1688752218232,"user":{"displayName":"JaeHyun Lee","userId":"13762872260843906568"},"user_tz":-540},"id":"7L5ZDMRuwEXc","outputId":"3e5b739b-66dd-4da8-fc30-66e20a8db6cc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape (original) :  torch.Size([2, 1, 2, 1, 2])\n","\n","\n","Shape (squeeze()) : torch.Size([2, 2, 2])\n","\n","\n","Shape (squeeze(0)) : torch.Size([2, 1, 2, 1, 2])\n","\n","\n","Shape (squeeze(1)) : torch.Size([2, 2, 1, 2])\n","\n","\n","Shape (squeeze(0,1,3)) : torch.Size([2, 2, 2])\n"]}],"source":["x = torch.zeros(2, 1, 2, 1, 2) # 모든 원소가 0인 (2,1,2,1,2) 크기를 가지는 텐서\n","print(\"Shape (original) : \", x.size()) # 원래 텐서 크기\n","print('\\n')\n","\n","print(\"Shape (squeeze()) :\", x.squeeze().size()) # 차원이 1인 차원이 여러개일 때, 모든 차원이 1인 차원 제거\n","print('\\n')\n","\n","print(\"Shape (squeeze(0)) :\", x.squeeze(0).size()) # 0번째 차원은 차원의 크기가 1이 아니므로, 변화 없음\n","print('\\n')\n","\n","print(\"Shape (squeeze(1)) :\", x.squeeze(1).size()) # 1번째 차원은 차원의 크기가 1이므로 제거\n","print('\\n')\n","\n","print(\"Shape (squeeze(0,1,3)) :\", x.squeeze((0, 1, 3)).size()) # 여러 차원 제거 가능 (0번째 차원은 차원의 크기가 1이 아니기 때문에 무시)"]},{"cell_type":"markdown","metadata":{"id":"HVctYQQrk1YV"},"source":["#### 📝 설명 : 텐서의 차원을 추가하거나 변경하는 방법에 대한 이해 및 실습\n","* expand : 텐서의 값을 반복하여 크기를 확장합니다.\n","  * A 텐서가 1차원일 경우 : A 텐서의 크기가 (m,) 이면 m은 고정하고 (x,m)의 크기로만 확장 가능\n","  * A 텐서가 2차원 이상일 경우 : 크기가 1인 차원에 대해서만 적용 가능. A 텐서의 크기가 (1,m) 이면 (x,m) , (m,1) 이면 (m,y) 로만 확장 가능.\n","\n","📚 참고할만한 자료:\n","* [expand] : https://pytorch.org/docs/stable/generated/torch.Tensor.expand.html\n"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1689146489609,"user":{"displayName":"Eddie(김윤기)","userId":"11850705511374304262"},"user_tz":-540},"id":"ZJIJUuZLxanz","outputId":"e9aaab48-cf52-461b-d427-593089d5be8a"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([1, 2, 3, 4])\n","Shape :  torch.Size([4])\n","\n","\n","tensor([[1, 2, 3, 4],\n","        [1, 2, 3, 4],\n","        [1, 2, 3, 4]])\n","Shape :  torch.Size([3, 4])\n"]}],"source":["tensor_1dim = torch.tensor([1, 2, 3, 4])\n","print(tensor_1dim)\n","print(\"Shape : \", tensor_1dim.size())\n","print('\\n')\n","\n","expand_tensor = tensor_1dim.expand(3, 4) # (,4) 를 (3,4) 의 크기로 확장 (값을 반복)\n","print(expand_tensor)\n","print(\"Shape : \", expand_tensor.size())"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":339},"executionInfo":{"elapsed":297,"status":"error","timestamp":1689146569339,"user":{"displayName":"Eddie(김윤기)","userId":"11850705511374304262"},"user_tz":-540},"id":"PYRKOkFlPXMY","outputId":"247fc402-d8d8-428f-d120-02398ca06510"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[1, 2, 3, 4],\n","        [1, 2, 3, 4]])\n","Shape :  torch.Size([2, 4])\n","\n","\n"]},{"ename":"RuntimeError","evalue":"The expanded size of the tensor (4) must match the existing size (2) at non-singleton dimension 0.  Target sizes: [4, 4].  Tensor sizes: [2, 4]","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[37], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape : \u001b[39m\u001b[38;5;124m\"\u001b[39m, tensor_2dim\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m expand_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtensor_2dim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (2,4) 를 (4,8) 의 크기로 확장 (값을 반복)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(expand_tensor) \u001b[38;5;66;03m# 에러 발생\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape : \u001b[39m\u001b[38;5;124m\"\u001b[39m, expand_tensor\u001b[38;5;241m.\u001b[39msize()) \u001b[38;5;66;03m# 에러 발생\u001b[39;00m\n","\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (4) must match the existing size (2) at non-singleton dimension 0.  Target sizes: [4, 4].  Tensor sizes: [2, 4]"]}],"source":["tensor_2dim = torch.tensor([[1, 2, 3, 4], [1, 2, 3, 4]]) # (2,4) 크기를 가진 Tensor\n","print(tensor_2dim)\n","print(\"Shape : \", tensor_2dim.size())\n","print('\\n')\n","\n","expand_tensor = tensor_2dim.expand(4,4) # (2,4) 를 (4,8) 의 크기로 확장 (값을 반복)\n","print(expand_tensor) # 에러 발생\n","print(\"Shape : \", expand_tensor.size()) # 에러 발생"]},{"cell_type":"markdown","metadata":{"id":"v-J0mAZ6k4OF"},"source":["#### 📝 설명 : 텐서의 차원을 추가하거나 변경하는 방법에 대한 이해 및 실습\n","* repeat : 텐서를 반복하여 크기를 확장합니다.\n","  * ex) A 텐서가 (m,n) 크기를 가진다하고, A 텐서를 repeat(i,j) 를 하면 결과값으로 (m x i, n x j)의 크기의 텐서가 생성됩니다.\n","\n","📚 참고할만한 자료:\n","* [repeat] : https://pytorch.org/docs/stable/generated/torch.Tensor.repeat.html"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1689146615597,"user":{"displayName":"Eddie(김윤기)","userId":"11850705511374304262"},"user_tz":-540},"id":"tJNvShg4ypAS","outputId":"51df633c-9565-4d7f-b3bd-fbcabe0aabe5"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([1, 2, 3, 4])\n","Shape :  torch.Size([4])\n","\n","\n","tensor([[1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4],\n","        [1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4],\n","        [1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4]])\n","Shape :  torch.Size([3, 16])\n"]}],"source":["tensor_1dim = torch.tensor([1, 2, 3, 4])\n","print(tensor_1dim)\n","print(\"Shape : \", tensor_1dim.size())\n","print('\\n')\n","\n","repeat_tensor = tensor_1dim.repeat(3, 4) # tensor_1dim 자체를 행으로 3번 반복, 열로 4번 반복\n","print(repeat_tensor)\n","print(\"Shape : \", repeat_tensor.size())"]},{"cell_type":"markdown","metadata":{"id":"83i37MGBk6lC"},"source":["#### 📝 설명 : 텐서의 차원을 추가하거나 변경하는 방법에 대한 이해 및 실습\n","* flatten : 다차원 텐서를 1차원 텐서로 변경합니다.\n","\n","📚 참고할만한 자료:\n","* [flatten] : https://pytorch.org/docs/stable/generated/torch.flatten.html"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":283,"status":"ok","timestamp":1689146657316,"user":{"displayName":"Eddie(김윤기)","userId":"11850705511374304262"},"user_tz":-540},"id":"nsZ6l_5kzUvv","outputId":"6fc16724-e88a-41e9-bae1-93a96bee058f"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[[ 0,  1],\n","         [ 2,  3],\n","         [ 4,  5],\n","         [ 6,  7],\n","         [ 8,  9]],\n","\n","        [[10, 11],\n","         [12, 13],\n","         [14, 15],\n","         [16, 17],\n","         [18, 19]]])\n","Shape :  torch.Size([2, 5, 2])\n","\n","\n","tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","        18, 19])\n","Shape :  torch.Size([20])\n"]}],"source":["t = torch.tensor([i for i in range(20)]).reshape(2, 5, 2) # 0부터 19까지의 숫자를 4행 5열 Tensor로 구성\n","print(t)\n","print(\"Shape : \", t.size())\n","print('\\n')\n","\n","flat_tensor = t.flatten() # (2, 5, 2) 의 Tensor를 (20,)로 모양 변경, 1차원으로 변경\n","print(flat_tensor)\n","print(\"Shape : \", flat_tensor.size())"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1688752313543,"user":{"displayName":"JaeHyun Lee","userId":"13762872260843906568"},"user_tz":-540},"id":"JraIVhtI0cCN","outputId":"bd5f3e43-cd55-4c82-8985-7448106e4ea8"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n","        [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]])\n","torch.Size([2, 10])\n"]}],"source":["flat_tensor2 = t.flatten(start_dim=1) # flatten을 시작할 차원을 지정할 수 있음. 지정한 차원 이후의 모든 차원을 하나의 차원으로 평면화, 기본값 = 0 (1차원)\n","print(flat_tensor2)\n","print(flat_tensor2.size())"]},{"cell_type":"markdown","metadata":{"id":"5Vnzd67tk9qn"},"source":["#### 📝 설명 : 텐서의 차원을 추가하거나 변경하는 방법에 대한 이해 및 실습\n","* ravel : 다차원 텐서를 1차원 텐서로 변경합니다.\n","\n","📚 참고할만한 자료:\n","* [ravel] : https://pytorch.org/docs/stable/generated/torch.ravel.html"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":427,"status":"ok","timestamp":1689146746775,"user":{"displayName":"Eddie(김윤기)","userId":"11850705511374304262"},"user_tz":-540},"id":"9vQ8tr-_z-eY","outputId":"8593fe1a-2f0d-4871-9a93-7fd918aafc90"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[[ 0,  1],\n","         [ 2,  3],\n","         [ 4,  5],\n","         [ 6,  7],\n","         [ 8,  9]],\n","\n","        [[10, 11],\n","         [12, 13],\n","         [14, 15],\n","         [16, 17],\n","         [18, 19]]])\n","Shape :  torch.Size([2, 5, 2])\n","\n","\n","tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","        18, 19])\n","Shape :  torch.Size([20])\n"]}],"source":["t = torch.tensor([i for i in range(20)]).reshape(2, 5, 2) # 0부터 19까지의 숫자를 (2, 5, 2) 크기 Tensor로 구성\n","print(t)\n","print(\"Shape : \", t.size())\n","print('\\n')\n","\n","ravel_tensor = t.ravel() # flatten 과 동일하게 (2,5,2) 의 텐서를 (20,)로 모양 변경, 1차원으로 변경\n","print(ravel_tensor)\n","print(\"Shape : \", ravel_tensor.size())"]},{"cell_type":"code","execution_count":42,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":174},"executionInfo":{"elapsed":269,"status":"error","timestamp":1689146755925,"user":{"displayName":"Eddie(김윤기)","userId":"11850705511374304262"},"user_tz":-540},"id":"bkwkNvwW1r4q","outputId":"fc6a7cfd-6300-4b15-af35-394662229d8b"},"outputs":[{"ename":"TypeError","evalue":"TensorBase.ravel() takes no arguments (1 given)","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# 에러 발생, ravel 은 flatten 과 달리 어떠한 축을 기준으로 평탄화 하는 작업이 없음\u001b[39;00m\n","\u001b[0;31mTypeError\u001b[0m: TensorBase.ravel() takes no arguments (1 given)"]}],"source":["t.ravel(1) # 에러 발생, ravel 은 flatten 과 달리 어떠한 축을 기준으로 평탄화 하는 작업이 없음"]},{"cell_type":"markdown","metadata":{"id":"W8ALfH-nkR7L"},"source":["### 2-3 역할이 비슷한 함수들의 차이 이해 및 실습\n","> 역할이 비슷한 함수들의 공통점과 차이점을 이해하고 활용할 수 있습니다."]},{"cell_type":"markdown","metadata":{"id":"o7k7Av2cUiL7"},"source":["#### 📝 설명 : 역할이 비슷한 함수들의 차이 이해 및 실습\n","* 모양 변경 : view vs. reshape vs. unsqueeze\n","  * ※ contiguous 란?\n","    * 텐서의 메모리 상에 연속적인 데이터 배치를 갖는 것\n","    * 텐서를 처음 생성 후 정의하면 기본적으로 contiguous 하지만, 이에 대해 차원의 순서를 변경하는 과정을 거치면 contiguous 하지 않습니다.\n","    * 텐서의 contiguous 함을 확인하기 위해선 is_contiguous() 를 사용합니다.\n","  * view 는 contiguous 하지 않은 텐서에 대해서 동작하지 않습니다.\n","  * reshape 는 contiguous 하지 않은 텐서를 contiguous 하게 만들어주고, 크기를 변경합니다.\n","  * unsqueeze 는 차원의 크기가 1인 차원을 추가하지만, 차원의 크기가 1이 아니면 차원의 모양을 변경할 수 없습니다.\n","\n","📚 참고할만한 자료:\n","* [what is contiguous?] : https://titania7777.tistory.com/3\n","* [view vs reshape] :  https://inmoonlight.github.io/2021/03/03/PyTorch-view-transpose-reshape/\n","* [view, reshape, transpose, permute 비교] : https://sanghyu.tistory.com/3"]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":229},"executionInfo":{"elapsed":270,"status":"error","timestamp":1689146930024,"user":{"displayName":"Eddie(김윤기)","userId":"11850705511374304262"},"user_tz":-540},"id":"kOLmpPvq7dW_","outputId":"5ccebce3-9777-44f5-b294-0b8b2df5436f"},"outputs":[{"name":"stdout","output_type":"stream","text":["False\n"]},{"ename":"RuntimeError","evalue":"view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[43], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m tmp_t \u001b[38;5;241m=\u001b[39m tmp\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# contiguous 를 False 로 만들기 위한 작업\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(tmp_t\u001b[38;5;241m.\u001b[39mis_contiguous()) \u001b[38;5;66;03m# contiguous 한지 검사\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtmp_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m) \u001b[38;5;66;03m# view는 contiguous 하지 않은 텐서에 대해선 동작이 되지 않음\u001b[39;00m\n","\u001b[0;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."]}],"source":["# view vs reshape\n","tmp = torch.tensor([[[0, 1], [2, 3], [4, 5]], \\\n","                 [[6, 7], [8, 9], [10, 11]], \\\n","                 [[12, 13], [14, 15], [16, 17]], \\\n","                 [[18, 19], [20, 21], [22, 23]]])\n","tmp_t = tmp.transpose(0,1) # contiguous 를 False 로 만들기 위한 작업\n","print(tmp_t.is_contiguous()) # contiguous 한지 검사\n","print(tmp_t.view(-1)) # view는 contiguous 하지 않은 텐서에 대해선 동작이 되지 않음"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":279,"status":"ok","timestamp":1689146964909,"user":{"displayName":"Eddie(김윤기)","userId":"11850705511374304262"},"user_tz":-540},"id":"pOgMDt6Q_NYO","outputId":"38817f49-5239-4b22-c724-e08f12f5a0bd"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([ 0,  1,  6,  7, 12, 13, 18, 19,  2,  3,  8,  9, 14, 15, 20, 21,  4,  5,\n","        10, 11, 16, 17, 22, 23])\n","True\n"]}],"source":["reshape_tmp = tmp_t.reshape(-1) # reshape은 contiguous 하지 않아도 동작이 됨\n","print(reshape_tmp)\n","print(reshape_tmp.is_contiguous()) # contiguous 하지 않았던 Tensor를 contiguous 하게 변경해 줌"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":286,"status":"ok","timestamp":1689146994151,"user":{"displayName":"Eddie(김윤기)","userId":"11850705511374304262"},"user_tz":-540},"id":"78nn8gTvtZW_","outputId":"3e3ac3d4-459c-4a8b-9f08-e31509c0b588"},"outputs":[{"name":"stdout","output_type":"stream","text":["View output size :  torch.Size([2, 3, 1])\n","Reshape output size :  torch.Size([2, 3, 1])\n","Unsqueeze output size :  torch.Size([2, 3, 1])\n"]}],"source":["# (view , reshape) vs unsqueeze\n","tensor_a = torch.randn(2, 3)\n","# (2, 3) 의 텐서를 (2, 3, 1)의 크기로 변경\n","view_tensor = tensor_a.view(2, 3, 1) # view 를 이용하여 (2,3,1) 의 크기로 변경\n","reshape_tensor = tensor_a.reshape(2, 3, 1) # reshape 를 이용하여 (2,3,1) 의 크기로 변경\n","unsqueeze_tensor = tensor_a.unsqueeze(-1) # unsqueeze 를 이용하여 (2,3,1) 의 크기로 변경\n","\n","print(\"View output size : \",view_tensor.size())\n","print(\"Reshape output size : \",reshape_tensor.size())\n","print(\"Unsqueeze output size : \",unsqueeze_tensor.size())"]},{"cell_type":"markdown","metadata":{"id":"7lS3Y-kslMWb"},"source":["#### 📝 설명 : 역할이 비슷한 함수들의 차이 이해 및 실습\n","* 차원 변경 : transpose vs. permute\n","  * transpose : 두 차원에 대해서만 변경이 가능\n","    * 인자가 총 2개여야함.\n","  * permute : 모든 차원에 대해서 변경이 가능\n","    * 인자가 차원의 개수와 동일해야 함.\n","\n","📚 참고할만한 자료:\n","* [view, reshape, transpose, permute 비교] : https://sanghyu.tistory.com/3"]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":281,"status":"ok","timestamp":1689147084017,"user":{"displayName":"Eddie(김윤기)","userId":"11850705511374304262"},"user_tz":-540},"id":"SjIPZQ753fHA","outputId":"dbd4aff4-f5da-4ed4-84f1-b3e7e3972bd7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Transpose tensor shape :  torch.Size([2, 2, 3])\n","Permute tensor shape :  torch.Size([2, 2, 3])\n"]}],"source":["import torch\n","tensor_a = torch.randn(2, 3, 2)\n","transpose_tensor = tensor_a.transpose(2, 1) # 행과 열을 전치\n","permute_tensor = tensor_a.permute(0, 2, 1) # 행과 열을 바꿈.\n","\n","print(\"Transpose tensor shape : \", transpose_tensor.size())\n","print(\"Permute tensor shape : \", permute_tensor.size())"]},{"cell_type":"markdown","metadata":{"id":"Z_wgTjTal4KZ"},"source":["#### 📝 설명 : 역할이 비슷한 함수들의 차이 이해 및 실습\n","* 반복을 통한 텐서 크기 확장 : expand vs. repeat\n","  * expand\n","    * 원본 텐서와 메모리를 공유한다.\n","  * repeat\n","    * 원본 텐서와 메모리를 공유하지 않는다.\n","\n","📚 참고할만한 자료:\n","* [expand vs repeat] : https://seducinghyeok.tistory.com/9"]},{"cell_type":"code","execution_count":47,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":524,"status":"ok","timestamp":1689147301242,"user":{"displayName":"Eddie(김윤기)","userId":"11850705511374304262"},"user_tz":-540},"id":"-p9i8pdE-2BF","outputId":"db801803-57a4-4e92-966a-4f23a1aa84fe"},"outputs":[{"name":"stdout","output_type":"stream","text":["Original Tensor Size\n","torch.Size([1, 1, 3])\n","tensor([[[0.1405, 0.2709, 0.4278]]])\n","\n","\n","Shape of expanded tensor: torch.Size([4, 1, 3])\n","\n","\n","Shape of repeated tensor: torch.Size([4, 1, 3])\n","\n","\n","Expanded Tensor\n","tensor([[[0., 0., 0.]],\n","\n","        [[0., 0., 0.]],\n","\n","        [[0., 0., 0.]],\n","\n","        [[0., 0., 0.]]])\n","\n","\n","Repeated Tensor\n","tensor([[[0.1405, 0.2709, 0.4278]],\n","\n","        [[0.1405, 0.2709, 0.4278]],\n","\n","        [[0.1405, 0.2709, 0.4278]],\n","\n","        [[0.1405, 0.2709, 0.4278]]])\n"]}],"source":["import torch\n","\n","# 원본 텐서 생성\n","tensor_a = torch.rand(1, 1, 3)\n","print('Original Tensor Size')\n","print(tensor_a.size())\n","print(tensor_a)\n","\n","print('\\n')\n","\n","# expand 사용하여 (1,1,3) => (4, 1, 3)\n","expand_tensor = tensor_a.expand(4, 1, -1)\n","print(\"Shape of expanded tensor:\", expand_tensor.size())\n","\n","print('\\n')\n","\n","# repeat 사용하여 (1,1,3) => (4, 1, 3)\n","repeat_tensor = tensor_a.repeat(4, 1, 1)\n","print(\"Shape of repeated tensor:\", repeat_tensor.size())\n","\n","print('\\n')\n","\n","# 평면화된 뷰 수정 후 원본 텐서 확인\n","tensor_a[:] = 0\n","\n","print(\"Expanded Tensor\")\n","print(expand_tensor) # 값 변경이 됨\n","\n","print('\\n')\n","\n","print(\"Repeated Tensor\")\n","print(repeat_tensor) # 깂 변경 안됨"]},{"cell_type":"markdown","metadata":{"id":"8yfcl7ZWnCBo"},"source":["## 3. 텐서 합치기 나누기\n","\n","```\n","💡 목차 개요 : 하나의 텐서를 여러가지로 나누는 방법과 여러 텐서를 하나의 텐서로 합치는 방법에 대해 이해하고 실습한다.\n","```\n","\n","- 3-1. 여러 텐서를 합치는 방법에 대한 이해 및 실습\n","- 3-2. 하나의 텐서를 여러 텐서로 나누는 방법에 대한 이해 및 실습\n"]},{"cell_type":"markdown","metadata":{"id":"OIZlhJQInf9e"},"source":["### 3-1 여러 텐서를 합치는 방법에 대한 이해 및 실습\n","\n","> 여러 텐서를 하나의 텐서로 합쳐서 새로운 텐서를 생성하는 과정을 알아봅니다.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"E6GaawUfqZvA"},"source":["#### 📝 설명 : 여러 텐서 합치기\n","* cat : 주어진 차원을 따라 텐서들을 연결합니다. (주어진 차원 외의 다른 차원의 크기가 같아야합니다.)\n","\n","📚 참고할만한 자료:\n","* [cat] : https://pytorch.org/docs/stable/generated/torch.cat.html"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":289,"status":"ok","timestamp":1689147386472,"user":{"displayName":"Eddie(김윤기)","userId":"11850705511374304262"},"user_tz":-540},"id":"umLxwbZdqxoR","outputId":"962f07ac-cbdc-4115-b4c4-384bbf724ee6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tensor A shape :  torch.Size([2, 3])\n","tensor([[6, 2, 8],\n","        [9, 6, 2]])\n","\n","\n","Tensor B shape :  torch.Size([5, 3])\n","tensor([[0.4130, 0.3782, 0.9512],\n","        [0.6084, 0.4798, 0.7604],\n","        [0.5092, 0.4620, 0.2436],\n","        [0.5249, 0.6107, 0.9544],\n","        [0.7920, 0.5896, 0.0908]])\n","\n","\n","Concat Tensor A and B (by row) Shape :  torch.Size([7, 3])\n","tensor([[6.0000, 2.0000, 8.0000],\n","        [9.0000, 6.0000, 2.0000],\n","        [0.4130, 0.3782, 0.9512],\n","        [0.6084, 0.4798, 0.7604],\n","        [0.5092, 0.4620, 0.2436],\n","        [0.5249, 0.6107, 0.9544],\n","        [0.7920, 0.5896, 0.0908]])\n"]}],"source":["tensor_a = torch.randint(1, 10, (2, 3)) # 1부터 9까지의 무작위 정수가 있는 (2,3) Tensor\n","tensor_b = torch.rand(5, 3) # 0부터 1까지의 균등분포를 따르는 (5,3) Tensor\n","\n","print(\"Tensor A shape : \", tensor_a.size())\n","print(tensor_a)\n","\n","print('\\n')\n","\n","print(\"Tensor B shape : \", tensor_b.size())\n","print(tensor_b)\n","\n","print('\\n')\n","\n","a_cat_b_row = torch.cat((tensor_a, tensor_b), dim=0) # dim = 0 (행), Tensor A 와 Tensor B 를 행 기준으로 합친다.\n","print(\"Concat Tensor A and B (by row) Shape : \", a_cat_b_row.shape) # (Tensor A 행 개수 + Tensor B 행 개수, Tensor A/B 열 개수)\n","print(a_cat_b_row)"]},{"cell_type":"markdown","metadata":{"id":"Z0F2JMPus3Xy"},"source":["#### 📝 설명 : 여러 텐서 합치기\n","* stack : 주어진 차원을 새로운 차원으로 추가하여 텐서들을 쌓습니다.\n","  * 합쳐질 텐서들의 크기는 모두 같아야합니다.\n","\n","📚 참고할만한 자료:\n","* [stack] : https://pytorch.org/docs/stable/generated/torch.stack.html"]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":270,"status":"ok","timestamp":1689147476932,"user":{"displayName":"Eddie(김윤기)","userId":"11850705511374304262"},"user_tz":-540},"id":"l8S9Dbrvs3Gx","outputId":"e8afae62-6153-42cc-babc-e1e883291184"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tensor A shape :  torch.Size([3, 2])\n","tensor([[3, 7],\n","        [3, 4],\n","        [6, 5]])\n","\n","\n","Tensor B shape :  torch.Size([3, 2])\n","tensor([[0.5996, 0.6841],\n","        [0.0847, 0.8715],\n","        [0.2819, 0.7655]])\n","\n","\n","Stack A and B (by row):  torch.Size([2, 3, 2])\n","tensor([[[3.0000, 7.0000],\n","         [3.0000, 4.0000],\n","         [6.0000, 5.0000]],\n","\n","        [[0.5996, 0.6841],\n","         [0.0847, 0.8715],\n","         [0.2819, 0.7655]]])\n"]}],"source":["tensor_a = torch.randint(1, 10, (3, 2))  # 1부터 9까지의 무작위 정수가 있는 (3,2) Tensor\n","tensor_b = torch.rand(3, 2)  # 0부터 1까지의 균등분포를 따르는 (3,2) Tensor\n","\n","print(\"Tensor A shape : \", tensor_a.size())\n","print(tensor_a)\n","\n","print('\\n')\n","\n","print(\"Tensor B shape : \", tensor_b.size())\n","print(tensor_b)\n","\n","print('\\n')\n","\n","stack_tensor_row = torch.stack([tensor_a, tensor_b], dim=0)  # dim = 0, 행을 기준으로 Tensor A 에 Tensor B 를 쌓기\n","print(\"Stack A and B (by row): \", stack_tensor_row.size()) # (쌓은 Tensor 개수, Tensor A/B 행 개수, Tensor A/B 열 개수)\n","print(stack_tensor_row)"]},{"cell_type":"markdown","metadata":{"id":"0jfYxwMLvPJ9"},"source":["### 3-2. 하나의 텐서를 여러 텐서로 나누는 방법에 대한 이해 및 실습\n","\n","> 하나의 텐서를 다양한 방법을 통해 여러 텐서로 나누는 과정을 알아봅니다."]},{"cell_type":"markdown","metadata":{"id":"hYsK5iOawR6I"},"source":["#### 📝 설명 : 텐서 나누기\n","* chunk : 나누고자 하는 **텐서의 개수**를 지정하여 원래의 텐서를 개수에 맞게 분리합니다.\n","  * chunks 인자\n","    * 몇 **개**의 텐서로 나눌 것인지\n","\n","📚 참고할만한 자료:\n","* [chunk] : https://pytorch.org/docs/stable/generated/torch.chunk.html"]},{"cell_type":"code","execution_count":50,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":293,"status":"ok","timestamp":1689147563316,"user":{"displayName":"Eddie(김윤기)","userId":"11850705511374304262"},"user_tz":-540},"id":"g7PRrBiFwRB1","outputId":"39526954-5ab0-49b7-8dd1-9315cef1747a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Original :  tensor([[5, 8, 6, 6],\n","        [3, 3, 9, 1],\n","        [6, 9, 6, 6],\n","        [8, 5, 1, 7],\n","        [1, 2, 8, 2],\n","        [5, 4, 5, 4]])\n","\n","\n","3 개의 Tensor로 분리\n","\n","\n","0 번째 Tensor \n","tensor([[5, 8, 6, 6],\n","        [3, 3, 9, 1]])\n","0 번째 Tensor 크기 torch.Size([2, 4])\n","------------------------------\n","1 번째 Tensor \n","tensor([[6, 9, 6, 6],\n","        [8, 5, 1, 7]])\n","1 번째 Tensor 크기 torch.Size([2, 4])\n","------------------------------\n","2 번째 Tensor \n","tensor([[1, 2, 8, 2],\n","        [5, 4, 5, 4]])\n","2 번째 Tensor 크기 torch.Size([2, 4])\n","------------------------------\n"]}],"source":["tensor_a = torch.randint(1, 10, (6, 4))  # (6,4) 텐서\n","print(\"Original : \", tensor_a)\n","\n","print('\\n')\n","\n","chunk_num = 3\n","chunk_tensor = torch.chunk(tensor_a, chunks = chunk_num, dim=0)  # dim = 0 (행), 6개의 행이 3개로 나누어 떨어지므로 3개의 텐서로 분리\n","print(f'{len(chunk_tensor)} 개의 Tensor로 분리')\n","\n","print('\\n')\n","\n","for idx,a in enumerate(chunk_tensor):\n","    print(f'{idx} 번째 Tensor \\n{a}')\n","    print(f'{idx} 번째 Tensor 크기', a.size())\n","    print('---'*10)"]},{"cell_type":"markdown","metadata":{"id":"iSrM4tYSv11K"},"source":["#### 📝 설명 : 텐서 나누기\n","* split : 입력한 **크기**로 여러 개의 작은 텐서로 나눕니다.\n","  * split_size_or_sections 인자\n","    * split_size (int): 얼마만큼의 크기로 자를 것인지\n","    * sections (list): 얼마만큼의 크기로 **각각** 자를 것인지 (리스트 형태로 각 텐서의 크기를 각각 지정해 줄 수 있음)\n","\n","📚 참고할만한 자료:\n","* [split] : https://pytorch.org/docs/stable/generated/torch.split.html"]},{"cell_type":"code","execution_count":51,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":759,"status":"ok","timestamp":1689147655702,"user":{"displayName":"Eddie(김윤기)","userId":"11850705511374304262"},"user_tz":-540},"id":"1H2ons4twDBU","outputId":"715b511a-3ffc-414c-e2ff-015b5f21cc9f"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[6, 8, 4, 9],\n","        [7, 9, 4, 5],\n","        [7, 3, 9, 5],\n","        [1, 4, 8, 9],\n","        [6, 1, 6, 1],\n","        [3, 6, 9, 7]])\n","\n","\n","3 개의 Tensor로 분리\n","\n","\n","0 번째 Tensor \n","tensor([[6, 8, 4, 9],\n","        [7, 9, 4, 5]])\n","0 번째 Tensor 크기 torch.Size([2, 4])\n","------------------------------\n","1 번째 Tensor \n","tensor([[7, 3, 9, 5],\n","        [1, 4, 8, 9]])\n","1 번째 Tensor 크기 torch.Size([2, 4])\n","------------------------------\n","2 번째 Tensor \n","tensor([[6, 1, 6, 1],\n","        [3, 6, 9, 7]])\n","2 번째 Tensor 크기 torch.Size([2, 4])\n","------------------------------\n"]}],"source":["tensor_a = torch.randint(1, 10, (6, 4))  # (6,4) 텐서\n","print(tensor_a)\n","\n","print('\\n')\n","\n","split_size = 2\n","split_tensor = torch.split(tensor_a , split_size_or_sections = split_size, dim=0)  # dim = 0 (행), 텐서 A 를 행의 길이가 2 (split_size)인 텐서로 나눔\n","print(f'{len(split_tensor)} 개의 Tensor로 분리')\n","\n","print('\\n')\n","\n","for idx,a in enumerate(split_tensor):\n","    print(f'{idx} 번째 Tensor \\n{a}')\n","    print(f'{idx} 번째 Tensor 크기', a.size())\n","    print('---'*10)"]},{"cell_type":"code","execution_count":52,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":270,"status":"ok","timestamp":1689147713081,"user":{"displayName":"Eddie(김윤기)","userId":"11850705511374304262"},"user_tz":-540},"id":"gH_brWAqxsJa","outputId":"5598d0b9-8ef4-4a06-de6d-1d42d1e6d41e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Original :  tensor([[3, 4, 2, 4],\n","        [2, 5, 5, 2],\n","        [5, 4, 4, 4],\n","        [6, 1, 9, 4],\n","        [7, 9, 5, 1],\n","        [1, 8, 6, 5]])\n","\n","\n","2 개의 Tensor로 분리\n","\n","\n","0 번째 Tensor \n","tensor([[3, 4, 2, 4],\n","        [2, 5, 5, 2]])\n","0 번째 Tensor 크기 torch.Size([2, 4])\n","------------------------------\n","1 번째 Tensor \n","tensor([[5, 4, 4, 4],\n","        [6, 1, 9, 4],\n","        [7, 9, 5, 1],\n","        [1, 8, 6, 5]])\n","1 번째 Tensor 크기 torch.Size([4, 4])\n","------------------------------\n"]}],"source":["tensor_a = torch.randint(1, 10, (6, 4))  # (6,4) 텐서\n","print(\"Original : \", tensor_a)\n","\n","print('\\n')\n","\n","split_num = [2, 4]\n","split_tensor = torch.split(tensor_a, split_size_or_sections = split_num, dim=0)  # dim = 0 (행), 텐서 A 를 행의 길이가 (2개인 텐서와 4개인 텐서)로 나눔\n","print(f'{len(split_tensor)} 개의 Tensor로 분리')\n","\n","print('\\n')\n","\n","for idx,a in enumerate(split_tensor):\n","    print(f'{idx} 번째 Tensor \\n{a}')\n","    print(f'{idx} 번째 Tensor 크기', a.size())\n","    print('---'*10)"]},{"cell_type":"markdown","metadata":{"id":"lSVO_LtU2erF"},"source":["#Reference\n","> <b><font color = green>(📒가이드)\n","- <a href='https://pytorch.org/docs/stable/index.html'>PyTorch 공식 문서</a>\n","- <a href='https://inmoonlight.github.io/2021/03/03/PyTorch-view-transpose-reshape/'>view, transpose, reshape 비교</a>"]},{"cell_type":"markdown","metadata":{"id":"4by_4X6tvaX6"},"source":["## Required Package\n","\n","> torch == 2.0.1"]},{"cell_type":"markdown","metadata":{"id":"-P3G5QSQvbSg"},"source":["## 콘텐츠 라이선스\n","\n","저작권 : <font color='blue'> <b> ©2023 by Upstage X fastcampus Co., Ltd. All rights reserved.</font></b>\n","\n","<font color='red'><b>WARNING</font> : 본 교육 콘텐츠의 지식재산권은 업스테이지 및 패스트캠퍼스에 귀속됩니다. 본 콘텐츠를 어떠한 경로로든 외부로 유출 및 수정하는 행위를 엄격히 금합니다. </b>"]}],"metadata":{"colab":{"gpuType":"T4","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
