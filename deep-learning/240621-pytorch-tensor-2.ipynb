{"cells":[{"cell_type":"markdown","metadata":{"id":"UKjg766IvMdI"},"source":["# í…ì„œ ì¡°ì‘ (2)"]},{"cell_type":"markdown","metadata":{"id":"OXUZV0j3nBJd"},"source":["## ì‹¤ìŠµ ê°œìš”\n","\n","1) **ì‹¤ìŠµ ëª©ì **\n","\n","\n","ì´ë²ˆ ì‹¤ìŠµì€ ì´ë¡ ìœ¼ë¡œ ë°°ì› ë˜ **PyTorchì˜ ì¡°ì‘ë²•**ì„ ì½”ë“œë¥¼ í†µí•´ í™•ì¸í•˜ê³  ìŠ¤ìŠ¤ë¡œ ì‹¤í–‰í•´ ë³¼ ìˆ˜ ìˆë„ë¡ êµ¬ì„±í•˜ì˜€ìŠµë‹ˆë‹¤. ì—¬ëŸ¬ ê°€ì§€ ì¡°ì‘ **ì˜ˆì‹œ**ë“¤ê³¼ ê·¸ì— ë”°ë¥¸ **ê²°ê³¼**ë¥¼ í†µí•´ PyTorchì˜ ì¡°ì‘ë²•ì„ ì‰½ê²Œ ìµí ìˆ˜ ìˆìŠµë‹ˆë‹¤.ğŸ˜Š\n","\n","\n","2) **ìˆ˜ê°• ëª©í‘œ**\n","\n","- í…ì„œì˜ ìˆ˜í•™ì ì¸ ì—°ì‚°ê³¼ broadcasting ì— ëŒ€í•œ ê°œë…ì„ ì´í•´í•˜ê³  ì‹¤í˜„í•  ìˆ˜ ìˆë‹¤. (<font color=red><b>Mathmatical Operations and Broadcasting</font></b>)\n","- Sparse Tensorì˜ ì¡°ì‘ë²•ì„ ìµí ìˆ˜ ìˆë‹¤. (<font color=red><b>Sparse Tensor</font></b>)"]},{"cell_type":"markdown","metadata":{"id":"H5CYPnoeDoRu"},"source":["### ì‹¤ìŠµ ëª©ì°¨\n","* 1. í…ì„œ ì—°ì‚° ë° ì¡°ì‘\n","  * 1-1. í…ì„œ ê°„ì˜ ê³„ì‚° ì‹¤ìŠµ\n","  * 1-2. Broadcasting ì„ ì´ìš©í•œ í…ì„œ ê°’ ë³€ê²½\n","  * 1-3. Broadcasting ì„ ì´ìš©í•œ ì°¨ì›ì´ ë‹¤ë¥¸ í…ì„œ ê°„ì˜ ê³„ì‚° ì‹¤ìŠµ\n","* 2. Sparse Tensor ì¡°ì‘ ë° ì‹¤ìŠµ\n","  * 2-1. COO Tensor ì— ëŒ€í•œ ì´í•´ ë° ì‹¤ìŠµ\n","  * 2-2. CSC/CSR Tensor ì— ëŒ€í•œ ì´í•´ ë° ì‹¤ìŠµ\n","  * 2-3. Sparse Tensorì˜ í•„ìš”ì„± ì´í•´ ë° ì‹¤ìŠµ\n","  * 2-4. Sparse Tensor ì˜ ì¡°ì‘ ì˜ˆì‹œ"]},{"cell_type":"markdown","metadata":{"id":"tMbQ5FwAX2Bl"},"source":["### í™˜ê²½ ì„¤ì •\n","> PyTorch ì„¤ì¹˜ ë° ë¶ˆëŸ¬ì˜¤ê¸°\n","\n","<font color = blue><b>\n","- íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë° ì„í¬íŠ¸\n","</font><b>"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"OW0tn1H4WVQA"},"outputs":[],"source":["import torch # PyTorch ë¶ˆëŸ¬ì˜¤ê¸°\n","import numpy as np # numpy ë¶ˆëŸ¬ì˜¤ê¸°\n","import warnings # ê²½ê³  ë¬¸êµ¬ ì œê±°\n","warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","metadata":{"id":"EZ118tS70iHF"},"source":["## 1. í…ì„œ ì—°ì‚° ë° ì¡°ì‘\n","\n","```\n","ğŸ’¡ ëª©ì°¨ ê°œìš” : í…ì„œì˜ ì—°ì‚°ì„ ì´í•´í•˜ê³ , ì—°ì‚° ê³¼ì • ì¤‘ broadcastingì´ ì–´ë–»ê²Œ ì ìš©ë˜ëŠ”ì§€ ì´í•´í•˜ê³  ì‹¤ìŠµí•œë‹¤.\n","```\n","\n","- 1-1. í…ì„œ ê°„ì˜ ê³„ì‚° ì‹¤ìŠµ\n","- 1-2. Broadcasting ì„ ì´ìš©í•œ í…ì„œ ê°’ ë³€ê²½\n","- 1-3. Broadcasting ì„ ì´ìš©í•œ ì°¨ì›ì´ ë‹¤ë¥¸ í…ì„œ ê°„ì˜ ê³„ì‚° ì‹¤ìŠµ\n"]},{"cell_type":"markdown","metadata":{"id":"ldTE5o1A1BWI"},"source":["### 1-1 í…ì„œ ê°„ì˜ ê³„ì‚° ì‹¤ìŠµ\n","> í…ì„œ ê°„ì˜ ê³„ì‚°ê³¼ í…ì„œ ë‚´ì˜ ê³„ì‚° ê³¼ì •ì„ ì•Œì•„ë´…ë‹ˆë‹¤.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"cun6rzXl1VXd"},"source":["#### ğŸ“ ì„¤ëª… : í…ì„œ ê°„ì˜ ì‚¬ì¹™ì—°ì‚°\n","* add : í…ì„œ ê°„ì˜ ë§ì…ˆì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. (+)\n","    * torch.add(a, b)\n","    * a.add(b)\n","    * a + b\n","* sub : í…ì„œ ê°„ì˜ ëº„ì…ˆì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. (-)\n","    * torch.sub(a, b)\n","    * a.sub(b)\n","    * a - b\n","* mul : í…ì„œ ê°„ì˜ ê³±ì…ˆì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. (*)\n","    * torch.mul(a, b)\n","    * a.mul(b)\n","    * a * b\n","* div : í…ì„œ ê°„ì˜ ë‚˜ëˆ—ì…ˆì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. (/)\n","    * torch.div(a, b)\n","    * a.div(b)\n","    * a / b\n","\n","ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:\n","* [add] https://pytorch.org/docs/stable/generated/torch.add.html\n","* [sub] https://pytorch.org/docs/stable/generated/torch.add.html\n","* [mul] https://pytorch.org/docs/stable/generated/torch.add.html\n","* [div] https://pytorch.org/docs/stable/generated/torch.add.html\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":381,"status":"ok","timestamp":1689149084807,"user":{"displayName":"Eddie(ê¹€ìœ¤ê¸°)","userId":"11850705511374304262"},"user_tz":-540},"id":"_WZBms6n10BJ","outputId":"bb26b457-e856-4327-c249-465b91a722b3"},"outputs":[{"name":"stdout","output_type":"stream","text":["ë§ì…ˆ\n","a+b : \n"," tensor([[ 3, -3],\n","        [ 5,  4]])\n","\n","\n","torch.add(a,b) : \n"," tensor([[ 3, -3],\n","        [ 5,  4]])\n","------------------------------\n","ëº„ì…ˆ\n","a-b : \n"," tensor([[-1,  1],\n","        [-1,  2]])\n","\n","\n","torch.sub(a,b) : \n"," tensor([[-1,  1],\n","        [-1,  2]])\n","------------------------------\n","ê³±ì…ˆ\n","a*b : \n"," tensor([[2, 2],\n","        [6, 3]])\n","\n","\n","torch.mul(a,b) : \n"," tensor([[2, 2],\n","        [6, 3]])\n","------------------------------\n","ë‚˜ëˆ—ì…ˆ\n","a/b : \n"," tensor([[0.5000, 0.5000],\n","        [0.6667, 3.0000]])\n","\n","\n","torch.div(a,b) : \n"," tensor([[0.5000, 0.5000],\n","        [0.6667, 3.0000]])\n"]}],"source":["tensor_a = torch.tensor([[1, -1], [2, 3]])\n","tensor_b = torch.tensor([[2, -2] ,[3, 1]])\n","\n","print('ë§ì…ˆ')\n","print(\"a+b : \\n\", tensor_a + tensor_b)\n","print('\\n')\n","print(\"torch.add(a,b) : \\n\", torch.add(tensor_a, tensor_b))\n","\n","print('---'*10)\n","\n","print('ëº„ì…ˆ')\n","print(\"a-b : \\n\", tensor_a - tensor_b)\n","print('\\n')\n","print(\"torch.sub(a,b) : \\n\", torch.sub(tensor_a, tensor_b))\n","\n","print('---'*10)\n","\n","print('ê³±ì…ˆ')\n","print(\"a*b : \\n\", tensor_a * tensor_b)\n","print('\\n')\n","print(\"torch.mul(a,b) : \\n\", torch.mul(tensor_a, tensor_b))\n","\n","print('---'*10)\n","\n","print('ë‚˜ëˆ—ì…ˆ')\n","print(\"a/b : \\n\", tensor_a / tensor_b)\n","print('\\n')\n","print(\"torch.div(a,b) : \\n\", torch.div(tensor_a, tensor_b))"]},{"cell_type":"markdown","metadata":{"id":"ov9gedcy3Lug"},"source":["#### ğŸ“ ì„¤ëª… : í…ì„œì˜ í†µê³„ì¹˜\n","í•¨ìˆ˜ì˜ dim íŒŒë¼ë¯¸í„° ê°’ì— ë”°ë¼ ê²°ê³¼ê°€ ë‹¬ë¼ì§€ëŠ” ê²ƒì„ ìœ ì˜í•˜ì„¸ìš”â—\n","* sum : í…ì„œì˜ ì›ì†Œë“¤ì˜ í•©ì„ ë°˜í™˜\n","\n","ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:\n","* [sum] : https://pytorch.org/docs/stable/generated/torch.sum.html"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":434,"status":"ok","timestamp":1688752385720,"user":{"displayName":"JaeHyun Lee","userId":"13762872260843906568"},"user_tz":-540},"id":"b6hQPfp9bF09","outputId":"155890d0-958f-4908-97c4-c2718a7e2734"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[1, 2],\n","        [3, 4]])\n","Shape :  torch.Size([2, 2])\n","\n","\n","dimension ì§€ì • ì•ˆí–ˆì„ ë•Œ :  tensor(10)\n","dim = 0 ì¼ ë•Œ :  tensor([4, 6])\n","dim = 1 ì¼ ë•Œ :  tensor([3, 7])\n"]}],"source":["tensor_a = torch.tensor([[1, 2], [3, 4]])\n","print(tensor_a)\n","print(\"Shape : \", tensor_a.size())\n","\n","print('\\n')\n","\n","print(\"dimension ì§€ì • ì•ˆí–ˆì„ ë•Œ : \", torch.sum(tensor_a))  # ëª¨ë“  ì›ì†Œì˜ í•©ì„ ë°˜í™˜ í•¨\n","print(\"dim = 0 ì¼ ë•Œ : \", torch.sum(tensor_a, dim=0))  # í–‰ì„ ê¸°ì¤€ (í–‰ ì¸ë±ìŠ¤ ë³€í™”)ìœ¼ë¡œ í•©í•¨ (0í–‰ 0ì—´ + 1í–‰ 0ì—´, 0í–‰ 1ì—´ + 1í–‰ 1ì—´)\n","print(\"dim = 1 ì¼ ë•Œ : \", torch.sum(tensor_a, dim=1)) # ì—´ì„ ê¸°ì¤€ (ì—´ ì¸ë±ìŠ¤ ë³€í™”)ìœ¼ë¡œ í•©í•¨ (0í–‰ 0ì—´ + 0í–‰ 1ì—´, 1í–‰ 0ì—´ + 1í–‰ 1ì—´)"]},{"cell_type":"markdown","metadata":{"id":"BMWbODjMcnbn"},"source":["#### ğŸ“ ì„¤ëª… : í…ì„œì˜ í†µê³„ì¹˜\n","í•¨ìˆ˜ì˜ dim íŒŒë¼ë¯¸í„° ê°’ì— ë”°ë¼ ê²°ê³¼ê°€ ë‹¬ë¼ì§€ëŠ” ê²ƒì„ ìœ ì˜í•˜ì„¸ìš”â—\n","* mean : í…ì„œì˜ ì›ì†Œë“¤ì˜ í‰ê· ì„ ë°˜í™˜\n","ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:\n","* [mean] : https://pytorch.org/docs/stable/generated/torch.mean.html"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":378,"status":"ok","timestamp":1688752387988,"user":{"displayName":"JaeHyun Lee","userId":"13762872260843906568"},"user_tz":-540},"id":"V7HMd6sPeBhM","outputId":"f57e74de-6650-4b9f-9f4b-7f83b521353a"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[1., 2.],\n","        [3., 4.]])\n","Shape :  torch.Size([2, 2])\n","\n","\n","dimension ì§€ì • ì•ˆí–ˆì„ ë•Œ :  tensor(2.5000)\n","dim = 0 ì¼ ë•Œ :  tensor([2., 3.])\n","dim = 1 ì¼ ë•Œ :  tensor([1.5000, 3.5000])\n"]}],"source":["tensor_a = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32) # mean ì€ ì‹¤ìˆ˜ê°€ ë‚˜ì˜¬ ìˆ˜ ìˆìœ¼ë¯€ë¡œ float ë¡œ ì§€ì •í•´ì£¼ì–´ì•¼ í•¨.\n","print(tensor_a)\n","print(\"Shape : \", tensor_a.size())\n","\n","print('\\n')\n","\n","print(\"dimension ì§€ì • ì•ˆí–ˆì„ ë•Œ : \", torch.mean(tensor_a))  # ëª¨ë“  ì›ì†Œì˜ í‰ê· ì„ ë°˜í™˜ í•¨\n","print(\"dim = 0 ì¼ ë•Œ : \", torch.mean(tensor_a, dim=0))  # í–‰ì„ ê¸°ì¤€ (í–‰ ì¸ë±ìŠ¤ ë³€í™”)ìœ¼ë¡œ í‰ê·  êµ¬í•¨ ((0í–‰ 0ì—´ + 1í–‰ 0ì—´)/2, (0í–‰ 1ì—´ + 1í–‰ 1ì—´)/2)\n","print(\"dim = 1 ì¼ ë•Œ : \", torch.mean(tensor_a, dim=1)) # ì—´ì„ ê¸°ì¤€ (ì—´ ì¸ë±ìŠ¤ ë³€í™”)ìœ¼ë¡œ í‰ê·  êµ¬í•¨ ((0í–‰ 0ì—´ + 0í–‰ 1ì—´)/2, (1í–‰ 0ì—´ + 1í–‰ 1ì—´)/2)"]},{"cell_type":"markdown","metadata":{"id":"sqp5T3a3c_yg"},"source":["#### ğŸ“ ì„¤ëª… : í…ì„œì˜ í†µê³„ì¹˜\n","í•¨ìˆ˜ì˜ dim íŒŒë¼ë¯¸í„° ê°’ì— ë”°ë¼ ê²°ê³¼ê°€ ë‹¬ë¼ì§€ëŠ” ê²ƒì„ ìœ ì˜í•˜ì„¸ìš”â—\n","* max : í…ì„œì˜ ì›ì†Œë“¤ì˜ ê°€ì¥ í° ê°’ì„ ë°˜í™˜\n","* min : í…ì„œì˜ ì›ì†Œë“¤ì˜ ê°€ì¥ ì‘ì€ ê°’ì„ ë°˜í™˜\n","\n","ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:\n","* [max] : https://pytorch.org/docs/stable/generated/torch.max.html\n","* [min] : https://pytorch.org/docs/stable/generated/torch.min.html"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":283,"status":"ok","timestamp":1688752390565,"user":{"displayName":"JaeHyun Lee","userId":"13762872260843906568"},"user_tz":-540},"id":"6sdl95xIek7r","outputId":"5d14d64f-99ef-4ac9-b54e-2b6ad11d8cda"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[1, 2],\n","        [3, 4]])\n","Shape :  torch.Size([2, 2])\n","\n","\n","dimension ì§€ì • ì•ˆí–ˆì„ ë•Œ :  tensor(4)\n","dim = 0 ì¼ ë•Œ :  tensor([3, 4])\n","dim = 1 ì¼ ë•Œ :  tensor([2, 4])\n","\n","\n","dimension ì§€ì • ì•ˆí–ˆì„ ë•Œ :  tensor(1)\n","dim = 0 ì¼ ë•Œ :  tensor([1, 2])\n","dim = 1 ì¼ ë•Œ :  tensor([1, 3])\n"]}],"source":["import torch\n","tensor_a = torch.tensor([[1, 2], [3, 4]])\n","print(tensor_a)\n","print(\"Shape : \", tensor_a.size())\n","print('\\n')\n","\n","print(\"dimension ì§€ì • ì•ˆí–ˆì„ ë•Œ : \", torch.max(tensor_a))  # ëª¨ë“  ì›ì†Œ ì¤‘ ìµœëŒ“ê°’ ë°˜í™˜\n","print(\"dim = 0 ì¼ ë•Œ : \", torch.max(tensor_a, dim=0).values)  # í–‰ì„ ê¸°ì¤€ (í–‰ ì¸ë±ìŠ¤ ë³€í™”)ìœ¼ë¡œ max ë¹„êµ (max(0í–‰ 0ì—´ , 1í–‰ 0ì—´), max(0í–‰ 1ì—´ , 1í–‰ 1ì—´))\n","print(\"dim = 1 ì¼ ë•Œ : \", torch.max(tensor_a, dim=1).values) # ì—´ì„ ê¸°ì¤€ (ì—´ ì¸ë±ìŠ¤ ë³€í™”)ìœ¼ë¡œ max ë¹„êµ (max(0í–‰ 0ì—´ , 0í–‰ 1ì—´), max(1í–‰ 0ì—´ , 1í–‰ 1ì—´))\n","print('\\n')\n","\n","print(\"dimension ì§€ì • ì•ˆí–ˆì„ ë•Œ : \", torch.min(tensor_a))  # ëª¨ë“  ì›ì†Œì˜ ìµœì†Ÿê°’ ë°˜í™˜ í•¨\n","print(\"dim = 0 ì¼ ë•Œ : \", torch.min(tensor_a, dim=0).values)  # í–‰ì„ ê¸°ì¤€ (í–‰ ì¸ë±ìŠ¤ ë³€í™”)ìœ¼ë¡œ min ë¹„êµ (min(0í–‰ 0ì—´ , 1í–‰ 0ì—´), min(0í–‰ 1ì—´ , 1í–‰ 1ì—´))\n","print(\"dim = 1 ì¼ ë•Œ : \", torch.min(tensor_a, dim=1).values) # ì—´ì„ ê¸°ì¤€ (ì—´ ì¸ë±ìŠ¤ ë³€í™”)ìœ¼ë¡œ min ë¹„êµ (min(0í–‰ 0ì—´ , 0í–‰ 1ì—´), min(1í–‰ 0ì—´ , 1í–‰ 1ì—´))"]},{"cell_type":"markdown","metadata":{"id":"E6iJItkFdT9F"},"source":["#### ğŸ“ ì„¤ëª… : í…ì„œì˜ í†µê³„ì¹˜\n","í•¨ìˆ˜ì˜ dim íŒŒë¼ë¯¸í„° ê°’ì— ë”°ë¼ ê²°ê³¼ê°€ ë‹¬ë¼ì§€ëŠ” ê²ƒì„ ìœ ì˜í•˜ì„¸ìš”â—\n","* argmax : í…ì„œì˜ ì›ì†Œë“¤ì˜ ê°€ì¥ í° ê°’ì˜ **ìœ„ì¹˜** ë°˜í™˜\n","* argmin : í…ì„œì˜ ì›ì†Œë“¤ì˜ ê°€ì¥ ì‘ì€ ê°’ì˜ **ìœ„ì¹˜** ë°˜í™˜\n","\n","ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:\n","* [argmax] : https://pytorch.org/docs/stable/generated/torch.argmax.html\n","* [argmin] : https://pytorch.org/docs/stable/generated/torch.argmin.html"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":448,"status":"ok","timestamp":1688752393199,"user":{"displayName":"JaeHyun Lee","userId":"13762872260843906568"},"user_tz":-540},"id":"MTJSU8rldTH2","outputId":"8db8db6d-d285-41a9-88e0-9309064b7b9b"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[1, 2],\n","        [3, 4]])\n","Shape :  torch.Size([2, 2])\n","\n","\n","dimension ì§€ì • ì•ˆí–ˆì„ ë•Œ :  tensor(3)\n","dim = 0 ì¼ ë•Œ :  tensor([1, 1])\n","dim = 1 ì¼ ë•Œ :  tensor([1, 1])\n","\n","\n","dimension ì§€ì • ì•ˆí–ˆì„ ë•Œ :  tensor(0)\n","dim = 0 ì¼ ë•Œ :  tensor([0, 0])\n","dim = 1 ì¼ ë•Œ :  tensor([0, 0])\n"]}],"source":["tensor_a = torch.tensor([[1, 2], [3, 4]])\n","print(tensor_a)\n","print(\"Shape : \",tensor_a.size())\n","print('\\n')\n","\n","print(\"dimension ì§€ì • ì•ˆí–ˆì„ ë•Œ : \", torch.argmax(tensor_a))  # ëª¨ë“  ì›ì†Œ ì¤‘ ìµœëŒ“ê°’ ìœ„ì¹˜ ë°˜í™˜í•¨\n","print(\"dim = 0 ì¼ ë•Œ : \", torch.argmax(tensor_a, dim=0))  # í–‰ì„ ê¸°ì¤€ (í–‰ ì¸ë±ìŠ¤ ë³€í™”)ìœ¼ë¡œ max ë¹„êµ (max(0í–‰ 0ì—´ , 1í–‰ 0ì—´), max(0í–‰ 1ì—´ , 1í–‰ 1ì—´)) => ìœ„ì¹˜ ë°˜í™˜\n","print(\"dim = 1 ì¼ ë•Œ : \", torch.argmax(tensor_a, dim=1)) # ì—´ì„ ê¸°ì¤€ (ì—´ ì¸ë±ìŠ¤ ë³€í™”)ìœ¼ë¡œ max ë¹„êµ (max(0í–‰ 0ì—´ , 0í–‰ 1ì—´), max(1í–‰ 0ì—´ , 1í–‰ 1ì—´)) => ìœ„ì¹˜ ë°˜í™˜\n","\n","print('\\n')\n","\n","print(\"dimension ì§€ì • ì•ˆí–ˆì„ ë•Œ : \", torch.argmin(tensor_a))  # ëª¨ë“  ì›ì†Œì˜ ìµœì†Ÿê°’ ìœ„ì¹˜ ë°˜í™˜ í•¨\n","print(\"dim = 0 ì¼ ë•Œ : \", torch.argmin(tensor_a, dim=0))  # í–‰ì„ ê¸°ì¤€ (í–‰ ì¸ë±ìŠ¤ ë³€í™”)ìœ¼ë¡œ min ë¹„êµ (min(0í–‰ 0ì—´ , 1í–‰ 0ì—´), min(0í–‰ 1ì—´ , 1í–‰ 1ì—´)) => ìœ„ì¹˜ ë°˜í™˜\n","print(\"dim = 1 ì¼ ë•Œ : \", torch.argmin(tensor_a, dim=1)) # ì—´ì„ ê¸°ì¤€ (ì—´ ì¸ë±ìŠ¤ ë³€í™”)ìœ¼ë¡œ min ë¹„êµ (min(0í–‰ 0ì—´ , 0í–‰ 1ì—´), min(1í–‰ 0ì—´ , 1í–‰ 1ì—´)) => ìœ„ì¹˜ ë°˜í™˜"]},{"cell_type":"markdown","metadata":{"id":"KZmeMd3agwBP"},"source":["#### ğŸ“ ì„¤ëª… : í–‰ë ¬ ë° ë²¡í„° ê³„ì‚°\n","* dot : **ë²¡í„°**ì˜ ë‚´ì  (inner product) ë°˜í™˜\n","  * torch.dot(a,b)\n","  * a.dot(b)\n","\n","ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:\n","* [dot] : https://pytorch.org/docs/stable/generated/torch.dot.html"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":291,"status":"ok","timestamp":1688752396024,"user":{"displayName":"JaeHyun Lee","userId":"13762872260843906568"},"user_tz":-540},"id":"rn2ZpS_whLTP","outputId":"a467651d-5e1c-4770-bf1f-2a52e8954f4c"},"outputs":[{"name":"stdout","output_type":"stream","text":["v1.dot(u1) :  tensor(11)\n","torch.dot(v1, u1) :  tensor(11)\n"]}],"source":["v1 = torch.tensor([1, 2])\n","u1 = torch.tensor([3, 4])\n","\n","print(\"v1.dot(u1) : \", v1.dot(u1)) # v1 ê³¼ u1 ë‚´ì  (torch.tensor ì—ë„ dot í•¨ìˆ˜ ì¡´ì¬)\n","print(\"torch.dot(v1, u1) : \", torch.dot(v1, u1)) # v1 ê³¼ u1 ë‚´ì "]},{"cell_type":"markdown","metadata":{"id":"hmDmTIy4hx1M"},"source":["#### ğŸ“ ì„¤ëª… : í–‰ë ¬ ë° ë²¡í„° ê³„ì‚°\n","* matmul : ë‘ í…ì„œ ê°„ì˜ í–‰ë ¬ê³± ë°˜í™˜ ***â€» ì›ì†Œ ê³±ê³¼ ë‹¤ë¦„ ì£¼ì˜â—***\n","  * torch.matmul(a,b)\n","  * a.matmul(b)\n","\n","ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:\n","* [matmul] : https://pytorch.org/docs/stable/generated/torch.matmul.html"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1689149537639,"user":{"displayName":"Eddie(ê¹€ìœ¤ê¸°)","userId":"11850705511374304262"},"user_tz":-540},"id":"aBADhk_tiIJO","outputId":"01ab4ebf-5dba-407d-d51a-2aec7bf63d2c"},"outputs":[{"name":"stdout","output_type":"stream","text":["A:  tensor([[1, 2],\n","        [3, 4]])\n","B:  tensor([[-1,  2],\n","        [ 1,  0]])\n","\n","\n","AB :  tensor([[1, 2],\n","        [1, 6]])\n","BA :  tensor([[5, 6],\n","        [1, 2]])\n"]}],"source":["A = torch.tensor([[1, 2], [3, 4]])  # (2,2) Tensor\n","B = torch.tensor([[-1, 2], [1, 0]])  # (2,2) Tensor\n","print(\"A: \", A)\n","print(\"B: \", B)\n","\n","print('\\n')\n","\n","print(\"AB : \", torch.matmul(A, B)) # Aì—ì„œ Bë¥¼ í–‰ë ¬ê³±\n","print(\"BA : \", B.matmul(A))  # Bì—ì„œ Aë¥¼ í–‰ë ¬ê³±"]},{"cell_type":"markdown","metadata":{"id":"DIifbNzskKm8"},"source":["### 1-2. Broadcasting ì„ ì´ìš©í•œ í…ì„œ ê°’ ë³€ê²½\n","> Broadcasting ì„ ì´ìš©í•˜ì—¬ í…ì„œì˜ ì›ì†Œë¥¼ ë³€ê²½í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ì´í•´í•˜ê³  ì‹¤ìŠµí•©ë‹ˆë‹¤."]},{"cell_type":"markdown","metadata":{"id":"hp7PE4F_kNvW"},"source":["#### ğŸ“ ì„¤ëª… : Broadcasting ì„ ì´ìš©í•œ í…ì„œ ì›ì†Œ ë³€ê²½\n","* scalar ê°’ìœ¼ë¡œ í…ì„œ ì›ì†Œ ë³€ê²½í•˜ê¸°\n","  * Indexingìœ¼ë¡œ í…ì„œ ì›ì†Œì— ì ‘ê·¼ í›„ scalar ê°’ìœ¼ë¡œ ì›ì†Œ ë³€ê²½\n","\n","ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:\n","* [Broadcasing semantics] : https://pytorch.org/docs/stable/notes/broadcasting.html"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":306,"status":"ok","timestamp":1689149701311,"user":{"displayName":"Eddie(ê¹€ìœ¤ê¸°)","userId":"11850705511374304262"},"user_tz":-540},"id":"0yapVKG4lLqX","outputId":"30874c17-fe9d-45b6-d576-498cd5ef514e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Original : \n"," tensor([[-1.2763, -0.6511],\n","        [-0.2358,  0.0203],\n","        [-1.2104, -0.9944]])\n","\n","\n","ë³€ê²½ëœ í…ì„œ : \n"," tensor([[10.0000, 10.0000],\n","        [-0.2358,  0.0203],\n","        [-1.2104, -0.9944]])\n"]}],"source":["tensor_a = torch.randn(3, 2)\n","print(\"Original : \\n\", tensor_a)\n","\n","print('\\n')\n","\n","## 0 í–‰ì˜ ëª¨ë“  ì—´ì„ 10 ìœ¼ë¡œ ë³€ê²½í•˜ê¸°\n","tensor_a[0, :] = 10 # 0í–‰ì˜ ëª¨ë“  ì—´ì— broadcasting ì„ í†µí•œ scalar ê°’ ëŒ€ì…\n","print(\"ë³€ê²½ëœ í…ì„œ : \\n\", tensor_a)"]},{"cell_type":"markdown","metadata":{"id":"ryUS3yIOnA-g"},"source":["#### ğŸ“ ì„¤ëª… : Broadcasting ì„ ì´ìš©í•œ í…ì„œ ì›ì†Œ ë³€ê²½\n","* í…ì„œ ê°’ìœ¼ë¡œ í…ì„œ ì›ì†Œ ë³€ê²½í•˜ê¸°\n","  * Indexingìœ¼ë¡œ í…ì„œ ì›ì†Œì— ì ‘ê·¼ í›„ í…ì„œ ê°’ìœ¼ë¡œ ì›ì†Œ ë³€ê²½\n","\n","ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:\n","* [Broadcasing semantics] : https://pytorch.org/docs/stable/notes/broadcasting.html"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":314,"status":"ok","timestamp":1689149746296,"user":{"displayName":"Eddie(ê¹€ìœ¤ê¸°)","userId":"11850705511374304262"},"user_tz":-540},"id":"lMQbXVrynEPp","outputId":"52fde8fe-e8b7-4af7-824b-b576ff76d07f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Original : \n"," tensor([[-0.4640,  0.6063],\n","        [ 0.1150,  2.0040],\n","        [-0.3974, -0.8116]])\n","\n","\n","ë³€ê²½ëœ Tensor : \n"," tensor([[0., 1.],\n","        [0., 1.],\n","        [0., 1.]])\n"]}],"source":["tensor_a = torch.randn(3, 2)\n","print(\"Original : \\n\", tensor_a)\n","\n","print('\\n')\n","\n","## ëª¨ë“  ê°’ì„ tensor [0,1]ë¡œ ë³€ê²½í•˜ê¸°\n","tensor_a[:, :] = torch.tensor([0, 1]) # ëª¨ë“  ê°’ì— ì ‘ê·¼í•˜ì—¬ [0,1] ë¡œ ë³€ê²½\n","print(\"ë³€ê²½ëœ Tensor : \\n\", tensor_a)"]},{"cell_type":"markdown","metadata":{"id":"_7ou_M9do-Zd"},"source":["### 1-3. Broadcasting ì„ ì´ìš©í•œ ì°¨ì›ì´ ë‹¤ë¥¸ í…ì„œ ê°„ì˜ ê³„ì‚° ì‹¤ìŠµ\n","> Broadcasting ì„ ì´ìš©í•˜ì—¬ ì°¨ì›ì´ ë‹¤ë¥¸ í…ì„œ ê°„ì˜ ê³„ì‚° ë°©ì‹ì— ëŒ€í•´ ì´í•´í•˜ê³  ì‹¤ìŠµí•©ë‹ˆë‹¤."]},{"cell_type":"markdown","metadata":{"id":"7AHbq1lgpgtd"},"source":["#### ğŸ“ ì„¤ëª… : Broadcasting ì„ ì´ìš©í•œ ê³„ì‚°\n","* ì°¨ì›ì´ ì„œë¡œ ë‹¤ë¥¸ í…ì„œ ê°„ì˜ ê³„ì‚°ì„ broadcasting ì„ í†µí•´ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n","\n","ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:\n","* [Broadcasing semantics] : https://pytorch.org/docs/stable/notes/broadcasting.html"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":323,"status":"ok","timestamp":1689149822271,"user":{"displayName":"Eddie(ê¹€ìœ¤ê¸°)","userId":"11850705511374304262"},"user_tz":-540},"id":"rM5KMdw6pqxq","outputId":"823ed4f0-bc94-4060-e26e-683d36b63390"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tensor A : \n"," tensor([[1., 0., 0.],\n","        [0., 1., 0.],\n","        [0., 0., 1.]])\n","\n","\n","Tensor B : \n"," tensor([1, 2, 3])\n","\n","\n","A + B : \n"," tensor([[2., 2., 3.],\n","        [1., 3., 3.],\n","        [1., 2., 4.]])\n"]}],"source":["tensor_a = torch.eye(3)\n","print(\"Tensor A : \\n\",tensor_a)\n","\n","print('\\n')\n","\n","tensor_b = torch.tensor([1, 2, 3])\n","print(\"Tensor B : \\n\", tensor_b)\n","\n","print('\\n')\n","\n","print('A + B : \\n', tensor_a + tensor_b) # broadcastingì„ í†µí•´ (3,) ì¸ Bê°€ (3,3)ìœ¼ë¡œ ë³€í™˜ë˜ì–´ ê³„ì‚° (í–‰ì˜ í™•ì¥)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1,"status":"ok","timestamp":1689149861027,"user":{"displayName":"Eddie(ê¹€ìœ¤ê¸°)","userId":"11850705511374304262"},"user_tz":-540},"id":"vp7Q-Ub7qmMi","outputId":"b14f4b7d-f36a-420e-808f-1fde8e3871f4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tensor A : \n"," tensor([[1., 0., 0.],\n","        [0., 1., 0.],\n","        [0., 0., 1.]])\n","\n","\n","Tensor B : \n"," tensor([[1],\n","        [2],\n","        [3]])\n","\n","\n","A + B : \n"," tensor([[2., 1., 1.],\n","        [2., 3., 2.],\n","        [3., 3., 4.]])\n"]}],"source":["tensor_a = torch.eye(3)\n","print(\"Tensor A : \\n\", tensor_a)\n","\n","print('\\n')\n","\n","tensor_b = torch.tensor([1, 2, 3]).reshape(3, 1) # í–‰ ë²¡í„°ë¡œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n","print(\"Tensor B : \\n\", tensor_b)\n","\n","print('\\n')\n","\n","print('A + B : \\n', tensor_a + tensor_b) # broadcastingì„ í†µí•´ (3,1) ì¸ Bê°€ (3,3)ìœ¼ë¡œ ë³€í™˜ë˜ì–´ ê³„ì‚° (ì—´ì˜ í™•ì¥)"]},{"cell_type":"markdown","metadata":{"id":"5J0V1R7rrFwj"},"source":["#### ğŸ“ ì„¤ëª… : Broadcasting ì„ ì´ìš©í•œ ê³„ì‚°\n","* ì°¨ì›ì˜ ë§ì§€ ì•ŠëŠ” ê²½ìš°, ì°¨ì›ì„ ì¶”ê°€í•˜ì—¬ broadcasting ìœ¼ë¡œ í…ì„œ ê°„ì˜ ê³„ì‚°ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n","\n","ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:\n","* [Broadcasing semantics] : https://pytorch.org/docs/stable/notes/broadcasting.html"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":266},"executionInfo":{"elapsed":4,"status":"error","timestamp":1689149935285,"user":{"displayName":"Eddie(ê¹€ìœ¤ê¸°)","userId":"11850705511374304262"},"user_tz":-540},"id":"3qlOVCdFrVQq","outputId":"ebadc45b-1a34-46e0-d2ee-56aa3d97866c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tensor size : torch.Size([3, 2, 5]), mean size : torch.Size([3, 2])\n","\n","\n"]},{"ename":"RuntimeError","evalue":"The size of tensor a (5) must match the size of tensor b (2) at non-singleton dimension 2","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[16], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensor size : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor_a\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, mean size : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmean_a\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtensor_a\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmean_a\u001b[49m)  \u001b[38;5;66;03m# ì—ëŸ¬ ë°œìƒ! ì°¨ì›ì´ ë‹¬ë¼ì„œ ê³„ì‚°ì´ ë˜ì§€ ì•ŠìŒ\u001b[39;00m\n","\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (5) must match the size of tensor b (2) at non-singleton dimension 2"]}],"source":["tensor_a = torch.randn(3, 2, 5)\n","mean_a = tensor_a.mean(2) # ì—´ ê¸°ì¤€ í‰ê· ê°’\n","print(f\"Tensor size : {tensor_a.size()}, mean size : {mean_a.size()}\")\n","\n","print('\\n')\n","\n","print(tensor_a - mean_a)  # ì—ëŸ¬ ë°œìƒ! ì°¨ì›ì´ ë‹¬ë¼ì„œ ê³„ì‚°ì´ ë˜ì§€ ì•ŠìŒ"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":326,"status":"ok","timestamp":1689149971280,"user":{"displayName":"Eddie(ê¹€ìœ¤ê¸°)","userId":"11850705511374304262"},"user_tz":-540},"id":"k9yknx4MtJ_6","outputId":"f7005a0b-33ff-455c-c391-b26fd6ed3567"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([3, 2, 1])\n","\n","\n","tensor([[[ 2.3126e-02,  4.4009e-01, -3.8365e-01,  6.2486e-01, -7.0441e-01],\n","         [ 5.0169e-01, -2.3717e-02, -6.5864e-01, -2.6497e-02,  2.0716e-01]],\n","\n","        [[ 8.1608e-01,  3.4825e-01,  7.3040e-01, -1.8974e+00,  2.6794e-03],\n","         [ 1.1102e-01, -5.6161e-01, -1.6277e-01,  8.1305e-01, -1.9969e-01]],\n","\n","        [[-8.4080e-01,  1.7350e+00,  3.0839e-01, -4.6323e-01, -7.3932e-01],\n","         [-3.3951e-01,  1.0937e+00, -2.8075e+00,  1.5205e+00,  5.3273e-01]]])\n"]}],"source":["# ì°¨ì› ìƒì„± í›„ broadcasting\n","unseq_mean = mean_a.unsqueeze(-1) # ë§ˆì§€ë§‰ ì¶• ì¶”ê°€\n","print(unseq_mean.size())\n","\n","print('\\n')\n","\n","print(tensor_a - unseq_mean)"]},{"cell_type":"markdown","metadata":{"id":"OYUG6flzvSmM"},"source":["## 2. Sparse Tensor ì¡°ì‘ ë° ì‹¤ìŠµ\n","\n","```\n","ğŸ’¡ ëª©ì°¨ ê°œìš” : ë‹¤ì–‘í•œ ì¢…ë¥˜ì˜ Sparse Tensor ë¥¼ ìƒì„±í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë³´ê³ , ì´ë¥¼ ì¡°ì‘í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì— ëŒ€í•´ ì•Œì•„ë´…ë‹ˆë‹¤.\n","```\n","\n","- 2-1. COO Tensor ì— ëŒ€í•œ ì´í•´ ë° ì‹¤ìŠµ\n","- 2-2. CSC/CSR Tensor ì— ëŒ€í•œ ì´í•´ ë° ì‹¤ìŠµ\n","- 2-3. Sparse Tensorì˜ í•„ìš”ì„± ì´í•´ ë° ì‹¤ìŠµ\n","- 2-4. Sparse Tensor ì˜ ì¡°ì‘ ì˜ˆì‹œ\n"]},{"cell_type":"markdown","metadata":{"id":"f3-Lx6q2vd_j"},"source":["### 2-1 COO Sparse Tensorì— ëŒ€í•œ ì‹¤ìŠµ\n","\n","> Sparse tensor ë¡œ ë³€í™˜í•˜ëŠ” ë°©ë²• ì¤‘ COO ë°©ì‹ì— ëŒ€í•´ ì•Œì•„ë³´ê³  ì‹¤ìŠµí•©ë‹ˆë‹¤."]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":343,"status":"ok","timestamp":1689150083919,"user":{"displayName":"Eddie(ê¹€ìœ¤ê¸°)","userId":"11850705511374304262"},"user_tz":-540},"id":"N4nXauTAvvfg","outputId":"3ff62a3c-e251-49d2-d717-16ca2fc59cf5"},"outputs":[{"data":{"text/plain":["tensor(indices=tensor([[0, 1],\n","                       [1, 0]]),\n","       values=tensor([2., 3.]),\n","       size=(2, 2), nnz=2, layout=torch.sparse_coo)"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["a = torch.tensor([[0, 2.], [3, 0]])\n","\n","a.to_sparse() # COO Sparse tensor ë¡œ ë³€í™˜"]},{"cell_type":"markdown","metadata":{"id":"Ba1dGmhBwQdQ"},"source":["#### ğŸ“ ì„¤ëª… : COO Sparse Tensor ìƒì„±\n","* sparse_coo_tensor : COO í˜•ì‹ì˜ sparse tensor ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜\n","  * indices : 0 ì´ ì•„ë‹Œ ê°’ì„ ê°€ì§„ í–‰,ì—´ì˜ ìœ„ì¹˜\n","  * values : 0 ì´ ì•„ë‹Œ ê°’\n","  * nnz : 0 ì´ ì•„ë‹Œ ê°’ì˜ ê°œìˆ˜\n","\n","\n","ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:\n","* [sparse_coo_tensor] : https://pytorch.org/docs/stable/generated/torch.sparse_coo_tensor.html"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":655,"status":"ok","timestamp":1689150498739,"user":{"displayName":"Eddie(ê¹€ìœ¤ê¸°)","userId":"11850705511374304262"},"user_tz":-540},"id":"TCrQh-h1ymGz","outputId":"1950efd8-d345-4ed5-a0e1-dc51f3641a36"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor(indices=tensor([[0, 1, 1],\n","                       [2, 0, 1]]),\n","       values=tensor([4, 5, 6]),\n","       size=(2, 3), nnz=3, layout=torch.sparse_coo)\n","\n","\n","tensor([[0, 0, 4],\n","        [5, 6, 0]])\n"]}],"source":["indices = torch.tensor([[0, 1, 1],[2, 0, 1]]) # 0ì´ ì•„ë‹Œ ê°’ì˜ (index, column) pairs\n","values = torch.tensor([4, 5, 6]) # 0 ì´ ì•„ë‹Œ ê°’ì˜ values, valuesì˜ ì‚¬ì´\n","sparse_tensor = torch.sparse_coo_tensor(indices = indices, values = values, size=(2, 3)) # (2,3)ì˜ sparse tensor\n","\n","print(sparse_tensor)\n","print('\\n')\n","print(sparse_tensor.to_dense())"]},{"cell_type":"markdown","metadata":{"id":"gTFuYUfYv1Cm"},"source":["### 2-2 CSR/CSC Sparse Tensorì— ëŒ€í•œ ì‹¤ìŠµ\n","\n","> Sparse tensor ë¡œ ë³€í™˜í•˜ëŠ” ë°©ë²• ì¤‘ CSR/CSC ë°©ì‹ì— ëŒ€í•´ ì•Œì•„ë³´ê³  ì‹¤ìŠµí•©ë‹ˆë‹¤."]},{"cell_type":"markdown","metadata":{"id":"ewY3PfLLrd-g"},"source":["#### ğŸ“ ì„¤ëª… : CSR Sparse Tensor ë¡œ ë³€í™˜\n","* to_sparse_csr : Dense tensorë¥¼ CSR í˜•ì‹ì˜ Sparse tensorë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜\n","  * crow_indices : 0 ì´ ì•„ë‹Œ ê°’ì„ ê°€ì§„ í–‰ì˜ ìœ„ì¹˜ (ì²«ë²ˆì§¸ëŠ” ë¬´ì¡°ê±´ 0)\n","  * col_indices : 0 ì´ ì•„ë‹Œ ê°’ì„ ê°€ì§„ ì—´ì˜ ìœ„ì¹˜\n","  * values : 0 ì´ ì•„ë‹Œ ê°’\n","  * nnz : 0 ì´ ì•„ë‹Œ ê°’ì˜ ê°œìˆ˜\n","  \n","ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:\n","* [csr] : https://pytorch.org/docs/stable/sparse.html#sparse-csr-docs\n"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":275,"status":"ok","timestamp":1688752421867,"user":{"displayName":"JaeHyun Lee","userId":"13762872260843906568"},"user_tz":-540},"id":"cK-8iVBUsdY3","outputId":"5afed4a7-8010-4c45-ab62-4a35b615374b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape :  torch.Size([2, 4])\n","tensor([[0, 0, 4, 3],\n","        [5, 6, 0, 0]])\n","\n","\n"]},{"data":{"text/plain":["tensor(crow_indices=tensor([0, 2, 4]),\n","       col_indices=tensor([2, 3, 0, 1]),\n","       values=tensor([4, 3, 5, 6]), size=(2, 4), nnz=4,\n","       layout=torch.sparse_csr)"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["t = torch.tensor([[0, 0, 4, 3], [5, 6, 0, 0]])\n","print(\"Shape : \", t.size())\n","print(t)\n","\n","print('\\n')\n","\n","t.to_sparse_csr()  # Dense Tensorë¥¼ CSR Sparse Tensor í˜•ì‹ìœ¼ë¡œ ë³€í™˜"]},{"cell_type":"markdown","metadata":{"id":"tvgls3yPr8Eb"},"source":["#### ğŸ“ ì„¤ëª… : CSC Sparse Tensor ë¡œ ë³€í™˜\n","* to_sparse_csc : Dense tensorë¥¼ CSC í˜•ì‹ì˜ Sparse tensorë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜\n","  * ccol_indices : 0 ì´ ì•„ë‹Œ ê°’ì˜ ì—´ ìœ„ì¹˜ (ì²«ë²ˆì§¸ ì›ì†ŒëŠ” ë¬´ì¡°ê±´ 0)\n","  * row_indices : 0 ì´ ì•„ë‹Œ ê°’ì˜ í–‰ ìœ„ì¹˜\n","  * values : 0 ì´ ì•„ë‹Œ ê°’ë“¤\n","  * nnz : 0 ì´ ì•„ë‹Œ ê°’ì˜ ê°œìˆ˜\n","  \n","ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:\n","* [csc] : https://pytorch.org/docs/stable/sparse.html#sparse-csc-docs"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":389,"status":"ok","timestamp":1688752424582,"user":{"displayName":"JaeHyun Lee","userId":"13762872260843906568"},"user_tz":-540},"id":"MZ4wlEButpT7","outputId":"c5a320a2-5a95-4171-e450-b00c21041f40"},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape :  torch.Size([2, 4])\n","tensor([[0, 0, 4, 3],\n","        [5, 6, 0, 0]])\n","\n","\n"]},{"data":{"text/plain":["tensor(ccol_indices=tensor([0, 1, 2, 3, 4]),\n","       row_indices=tensor([1, 1, 0, 0]),\n","       values=tensor([5, 6, 4, 3]), size=(2, 4), nnz=4,\n","       layout=torch.sparse_csc)"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["t = torch.tensor([[0, 0, 4, 3], [5, 6, 0, 0]])\n","print(\"Shape : \", t.size())\n","print(t)\n","\n","print('\\n')\n","\n","t.to_sparse_csc()  # Dense Tensor ë¥¼ CSC Spare tensor í˜•ì‹ìœ¼ë¡œ ë³€í™˜"]},{"cell_type":"markdown","metadata":{"id":"BidxZpX-sikK"},"source":["#### ğŸ“ ì„¤ëª… : CSR Sparse Tensor ìƒì„±\n","* sparse_csr_tensor : CSR í˜•ì‹ì˜ Sparse tensor ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜\n","\n","ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:\n","* [sparse_csr_tensor] : https://pytorch.org/docs/stable/generated/torch.sparse_csr_tensor.html"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":297,"status":"ok","timestamp":1689150928283,"user":{"displayName":"Eddie(ê¹€ìœ¤ê¸°)","userId":"11850705511374304262"},"user_tz":-540},"id":"KGQwgI2Iubt9","outputId":"1742f496-5ae3-46bb-e795-78e78631fb5f"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor(crow_indices=tensor([0, 2, 2]),\n","       col_indices=tensor([0, 1]),\n","       values=tensor([1, 2]), size=(2, 2), nnz=2, layout=torch.sparse_csr)\n","\n","\n","tensor([[1, 2],\n","        [0, 0]])\n"]}],"source":["crow_indices = torch.tensor([0, 2, 2]) # 0ì´ ì•„ë‹Œ í–‰ì˜ ìœ„ì¹˜ (ì²«ë²ˆì¨°ëŠ” ë¬´ì¡°ê±´ 0), ì¦‰ row_pointer\n","col_indices = torch.tensor([0, 1]) # 0ì´ ì•„ë‹Œ ì—´ì˜ ìœ„ì¹˜\n","values = torch.tensor([1, 2]) # 0ì´ ì•„ë‹Œ ê°’\n","csr = torch.sparse_csr_tensor(crow_indices = crow_indices, col_indices = col_indices, values = values)\n","\n","print(csr)\n","print('\\n')\n","print(csr.to_dense())"]},{"cell_type":"markdown","metadata":{"id":"cQRzTsDXs5V0"},"source":["#### ğŸ“ ì„¤ëª… : CSC Sparse Tensor ìƒì„±\n","* sparse_csc_tensor : CSC í˜•ì‹ì˜ Sparse tensor ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜\n","\n","ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:\n","* [sparse_csc_tensor] : https://pytorch.org/docs/stable/generated/torch.sparse_csc_tensor.html"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1,"status":"ok","timestamp":1689150854835,"user":{"displayName":"Eddie(ê¹€ìœ¤ê¸°)","userId":"11850705511374304262"},"user_tz":-540},"id":"zZ5iVQMRvEH3","outputId":"d3aaa223-79a3-4f05-ae29-4bca1b3fbff6"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor(ccol_indices=tensor([0, 2, 2]),\n","       row_indices=tensor([0, 1]),\n","       values=tensor([1, 2]), size=(2, 2), nnz=2, layout=torch.sparse_csc)\n","\n","\n","tensor([[1, 0],\n","        [2, 0]])\n"]}],"source":["ccol_indices = torch.tensor([0, 2, 2]) # 0ì´ ì•„ë‹Œ ì—´ì˜ ìœ„ì¹˜ (ì²«ë²ˆì¨°ëŠ” ë¬´ì¡°ê±´ 0), ì¦‰ column_pointer\n","row_indices = torch.tensor([0, 1]) # 0ì´ ì•„ë‹Œ í–‰ì˜ ìœ„ì¹˜\n","values = torch.tensor([1, 2]) # 0ì´ ì•„ë‹Œ ê°’\n","csc = torch.sparse_csc_tensor(ccol_indices = ccol_indices, row_indices = row_indices, values = values)\n","\n","print(csc)\n","print('\\n')\n","print(csc.to_dense())"]},{"cell_type":"markdown","metadata":{"id":"4hQgE14lvWJO"},"source":["### 2-3 Sparse Tensorì˜ í•„ìš”ì„± ì´í•´ ë° ì‹¤ìŠµ\n","\n","> Dense tensorê°€ ê°€ì§€ëŠ” í•œê³„ì ì— ëŒ€í•´ ì´í•´í•˜ê³ , Sparse tensor ê°€ í•„ìš”í•œ ì´ìœ ì— ëŒ€í•´ ì•Œì•„ë´…ë‹ˆë‹¤."]},{"cell_type":"markdown","metadata":{"id":"bBeGk-dYxVt0"},"source":["#### ğŸ“ ì„¤ëª… : Sparse Tensor ì˜ í•„ìš”ì„±\n","* ì•„ì£¼ í° í¬ê¸°ì˜ matrix ë¥¼ êµ¬ì„±í•  ë•Œ, ì¼ë°˜ì ì¸ dense tensor ëŠ” ë©”ëª¨ë¦¬ ì•„ì›ƒ í˜„ìƒì´ ë°œìƒí•˜ì§€ë§Œ, sparse tensor ëŠ” ë©”ëª¨ë¦¬ ì•„ì›ƒí˜„ìƒì´ ë°œìƒí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n","  * to_dense() : sparse tensor ë¥¼ dense tensor ë¡œ ë§Œë“œëŠ” í•¨ìˆ˜"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"Z-sKmel6o5yk"},"outputs":[],"source":["i = torch.randint(0, 100000, (200000,)).reshape(2, -1)\n","v = torch.rand(100000)\n","coo_sparse_tensor = torch.sparse_coo_tensor(indices = i, values = v, size = [100000, 100000]) # COO Sparse Tensor (100000 x 100000)"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1,"status":"ok","timestamp":1689151188482,"user":{"displayName":"Eddie(ê¹€ìœ¤ê¸°)","userId":"11850705511374304262"},"user_tz":-540},"id":"vIAhKakiuDU6","outputId":"f88a865e-2ed9-485c-b9a7-7670c7b01f82"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n","\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n","\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["crow = torch.randint(0, 100000, (100000,))\n","col = torch.randint(0, 100000, (100000,))\n","v = torch.rand(100000)\n","csr_sparse_tensor = torch.sparse_csr_tensor(crow_indices = crow, col_indices = col, values = v) # CSR Sparse Tensor (100000 x 100000)"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"D2ypY-75p112"},"outputs":[],"source":["coo_sparse_tensor.to_dense() # COO í˜•ì‹ìœ¼ë¡œ ë§Œë“¤ì–´ì§„ Sparse Tensor ë¥¼ Dense Tensor ë¡œ ë³€í™˜ , ë©”ëª¨ë¦¬ ì•„ì›ƒ"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"T0ZvMku8Qy_f"},"outputs":[],"source":["import torch # ì»¤ë„ ì¬ì‹œì‘ í•˜ê¸°ì— ë‹¤ì‹œ torch library ë¡œë“œ"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"gCLXEXERTUJ3"},"outputs":[{"ename":"NameError","evalue":"name 'csr_sparse_tensor' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcsr_sparse_tensor\u001b[49m\u001b[38;5;241m.\u001b[39mto_dense() \u001b[38;5;66;03m# CSR í˜•ì‹ìœ¼ë¡œ ë§Œë“¤ì–´ì§„ Sparse Tensor ë¥¼ Dense Tensor ë¡œ ë³€í™˜ , ë©”ëª¨ë¦¬ ì•„ì›ƒ\u001b[39;00m\n","\u001b[0;31mNameError\u001b[0m: name 'csr_sparse_tensor' is not defined"]}],"source":["csr_sparse_tensor.to_dense() # CSR í˜•ì‹ìœ¼ë¡œ ë§Œë“¤ì–´ì§„ Sparse Tensor ë¥¼ Dense Tensor ë¡œ ë³€í™˜ , ë©”ëª¨ë¦¬ ì•„ì›ƒ"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"5ad4Iu5aQ9dd"},"outputs":[],"source":["import torch # ì»¤ë„ ì¬ì‹œì‘ í•˜ê¸°ì— ë‹¤ì‹œ torch library ë¡œë“œ"]},{"cell_type":"markdown","metadata":{"id":"cOYA2R66v46l"},"source":["### 2-4 Sparse Tensorì˜ ì¡°ì‘ ë°©ë²•\n","\n","> Sparse tensor ì˜ Indexing ê³¼ ì—°ì‚° ë°©ë²•ì— ëŒ€í•´ ì•Œì•„ë´…ë‹ˆë‹¤."]},{"cell_type":"markdown","metadata":{"id":"tD8jNabnxepy"},"source":["#### ğŸ“ ì„¤ëª… : Sparse Tensor ì˜ ì—°ì‚° (=2ì°¨ì›)\n","* 2ì°¨ì› sparse tensor ê°„ì—ëŠ” ì¼ë°˜ í…ì„œì™€ ë™ì¼í•˜ê²Œ ì‚¬ì¹™ì—°ì‚° í•¨ìˆ˜ë“¤ê³¼ í–‰ë ¬ê³±ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n","\n","ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:\n","* [sparse] : https://pytorch.org/docs/stable/sparse.html"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":322,"status":"ok","timestamp":1689151328420,"user":{"displayName":"Eddie(ê¹€ìœ¤ê¸°)","userId":"11850705511374304262"},"user_tz":-540},"id":"06ZsXbnOv38R","outputId":"dbafb688-bdec-4ede-ce7d-103393d9ade7"},"outputs":[{"name":"stdout","output_type":"stream","text":["ë§ì…ˆ\n","tensor([[True, True],\n","        [True, True]])\n","\n","\n","ê³±ì…ˆ\n","tensor([[True, True],\n","        [True, True]])\n","\n","\n","í–‰ë ¬ê³±\n","tensor([[True, True],\n","        [True, True]])\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_22062/3038429869.py:18: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n","  print(torch.matmul(a, b).to_dense() == torch.matmul(sparse_a, sparse_b).to_dense())\n"]}],"source":["# Sparse ì™€ Sparse Tensor ê°„ì˜ ì—°ì‚° (2ì°¨ì›)\n","a = torch.tensor([[0, 1], [0, 2]], dtype=torch.float)\n","b = torch.tensor([[1, 0],[0, 0]], dtype=torch.float)\n","\n","sparse_a = a.to_sparse()\n","sparse_b = b.to_sparse()\n","\n","print('ë§ì…ˆ')\n","print(torch.add(a, b).to_dense() == torch.add(sparse_a, sparse_b).to_dense())\n","\n","print('\\n')\n","print('ê³±ì…ˆ')\n","print(torch.mul(a, b).to_dense() == torch.mul(sparse_a, sparse_b).to_dense())\n","\n","print('\\n')\n","\n","print('í–‰ë ¬ê³±')\n","print(torch.matmul(a, b).to_dense() == torch.matmul(sparse_a, sparse_b).to_dense())"]},{"cell_type":"markdown","metadata":{"id":"QNxWiMSij8A-"},"source":["#### ğŸ“ ì„¤ëª… : Sparse Tensor ì˜ ì—°ì‚° (=3ì°¨ì›)\n","* 3ì°¨ì› sparse tensor ì—ëŠ” ì¼ë°˜ í…ì„œì™€ ë™ì¼í•˜ê²Œ ì‚¬ì¹™ì—°ì‚° í•¨ìˆ˜ë“¤ì€ ì‚¬ìš© ê°€ëŠ¥í•˜ì§€ë§Œ í–‰ë ¬ê³±ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n","  * CSR/CSC í˜•ì‹ì—ì„œëŠ” ê³±ì…ˆë„ 3ì°¨ì›ì—ì„  ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.\n","* ì´ëŠ” sparse tensor ì™€ sparse tensor ê°„ì—ë„ ì ìš©ì´ ë˜ê³ , sparse tensor ì™€ dense tensor ê°„ì˜ ì—°ì‚°ì—ë„ ì ìš©ì´ ë©ë‹ˆë‹¤."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1091,"status":"error","timestamp":1689151417573,"user":{"displayName":"Eddie(ê¹€ìœ¤ê¸°)","userId":"11850705511374304262"},"user_tz":-540},"id":"UZFYPnQGjezX","outputId":"81d642fd-e1ed-4ed7-8b81-4d3b82f5a2e7"},"outputs":[{"name":"stdout","output_type":"stream","text":["ë§ì…ˆ\n","tensor([[[True, True],\n","         [True, True]],\n","\n","        [[True, True],\n","         [True, True]]])\n","\n","\n","ê³±ì…ˆ\n","tensor([[[True, True],\n","         [True, True]],\n","\n","        [[True, True],\n","         [True, True]]])\n","\n","\n","í–‰ë ¬ê³±\n"]},{"ename":"RuntimeError","evalue":"expand is unsupported for Sparse tensors","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[5], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mí–‰ë ¬ê³±\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mmatmul(a, b)\u001b[38;5;241m.\u001b[39mto_dense() \u001b[38;5;241m==\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparse_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse_b\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto_dense()) \u001b[38;5;66;03m# ì—ëŸ¬ ë°œìƒ\u001b[39;00m\n","\u001b[0;31mRuntimeError\u001b[0m: expand is unsupported for Sparse tensors"]}],"source":["# Sparse ì™€ Sparse Tensor ê°„ì˜ ì—°ì‚° (3ì°¨ì›)\n","a = torch.tensor([[[0, 1], [0, 2]], [[0, 1], [0, 2]]], dtype=torch.float)\n","b = torch.tensor([[[1, 0],[0, 0]], [[1, 0], [0, 0]]], dtype=torch.float)\n","\n","sparse_a = a.to_sparse()\n","sparse_b = b.to_sparse()\n","\n","print('ë§ì…ˆ')\n","print(torch.add(a, b).to_dense() == torch.add(sparse_a, sparse_b).to_dense())\n","\n","print('\\n')\n","print('ê³±ì…ˆ')\n","print(torch.mul(a, b).to_dense() == torch.mul(sparse_a, sparse_b).to_dense())\n","\n","print('\\n')\n","\n","print('í–‰ë ¬ê³±')\n","print(torch.matmul(a, b).to_dense() == torch.matmul(sparse_a, sparse_b).to_dense()) # ì—ëŸ¬ ë°œìƒ"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":496,"status":"ok","timestamp":1689151468214,"user":{"displayName":"Eddie(ê¹€ìœ¤ê¸°)","userId":"11850705511374304262"},"user_tz":-540},"id":"JkMRIqI4kZUX","outputId":"f241d42b-df52-456e-b81d-245eb5f9bca1"},"outputs":[{"name":"stdout","output_type":"stream","text":["ë§ì…ˆ\n","tensor([[True, True],\n","        [True, True]])\n","\n","\n","ê³±ì…ˆ\n","tensor([[True, True],\n","        [True, True]])\n","\n","\n","í–‰ë ¬ê³±\n","tensor([[True, True],\n","        [True, True]])\n"]}],"source":["# Dense ì™€ Sparse Tensor ê°„ì˜ ì—°ì‚° (2ì°¨ì›)\n","a = torch.tensor([[0,1],[0,2]],dtype=torch.float)\n","b = torch.tensor([[1,0],[0,0]],dtype=torch.float).to_sparse()\n","\n","sparse_b = b.to_sparse()\n","\n","print('ë§ì…ˆ')\n","print(torch.add(a, b).to_dense() == torch.add(a, sparse_b).to_dense())\n","\n","print('\\n')\n","print('ê³±ì…ˆ')\n","print(torch.mul(a, b).to_dense() == torch.mul(a, sparse_b).to_dense())\n","\n","print('\\n')\n","\n","print('í–‰ë ¬ê³±')\n","print(torch.matmul(a, b).to_dense() == torch.matmul(a, sparse_b).to_dense())"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":5,"status":"error","timestamp":1688799085394,"user":{"displayName":"ê¹€ì˜ë¯¼","userId":"04915862517565535031"},"user_tz":-540},"id":"kcZEH-sedkpI","outputId":"624ec917-cf3f-47b6-a908-887972fcc304"},"outputs":[{"name":"stdout","output_type":"stream","text":["ë§ì…ˆ\n","tensor([[[True, True],\n","         [True, True]],\n","\n","        [[True, True],\n","         [True, True]]])\n","\n","\n","ê³±ì…ˆ\n","tensor([[[True, True],\n","         [True, True]],\n","\n","        [[True, True],\n","         [True, True]]])\n","\n","\n","í–‰ë ¬ê³±\n"]},{"ename":"RuntimeError","evalue":"expand is unsupported for Sparse tensors","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[7], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mí–‰ë ¬ê³±\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mmatmul(a, b)\u001b[38;5;241m.\u001b[39mto_dense() \u001b[38;5;241m==\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse_b\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto_dense()) \u001b[38;5;66;03m# ì—ëŸ¬ ë°œìƒ\u001b[39;00m\n","\u001b[0;31mRuntimeError\u001b[0m: expand is unsupported for Sparse tensors"]}],"source":["a = torch.tensor([[[0, 1], [0, 2]], [[0, 1], [0, 2]]],dtype=torch.float)\n","b = torch.tensor([[[1, 0], [0, 0]], [[1, 0], [0, 0]]],dtype=torch.float)\n","\n","sparse_b = b.to_sparse()\n","\n","print('ë§ì…ˆ')\n","print(torch.add(a, b).to_dense() == torch.add(a, sparse_b).to_dense())\n","\n","print('\\n')\n","print('ê³±ì…ˆ')\n","print(torch.mul(a, b).to_dense() == torch.mul(a, sparse_b).to_dense())\n","\n","print('\\n')\n","\n","print('í–‰ë ¬ê³±')\n","print(torch.matmul(a, b).to_dense() == torch.matmul(a, sparse_b).to_dense()) # ì—ëŸ¬ ë°œìƒ"]},{"cell_type":"markdown","metadata":{"id":"wR92561My19i"},"source":["#### ğŸ“ ì„¤ëª… : Sparse Tensor ì˜ Indexing\n","* ì¼ë°˜ í…ì„œì™€ ë™ì¼í•˜ê²Œ indexing ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n","  * slicing (\":\" ì„ ì‚¬ìš©)ì€ ë¶ˆê°€ëŠ¥ í•©ë‹ˆë‹¤.\n","  \n","ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:\n","* [sparse] : https://pytorch.org/docs/stable/sparse.html"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":346,"status":"ok","timestamp":1689151604234,"user":{"displayName":"Eddie(ê¹€ìœ¤ê¸°)","userId":"11850705511374304262"},"user_tz":-540},"id":"Hi9s2FBIy7cL","outputId":"8ba32db0-e6e3-4d91-afab-08d57b79388b"},"outputs":[{"name":"stdout","output_type":"stream","text":["2ì°¨ì› Sparse Tensor ì¸ë±ì‹±\n","tensor([True, True])\n","\n","\n","3ì°¨ì› Sprase Tensor ì¸ë±ì‹±\n","tensor([[True, True],\n","        [True, True]])\n"]}],"source":["a = torch.tensor([[0,1 ], [0, 2]], dtype=torch.float)\n","b = torch.tensor([[[1, 0], [0, 0]], [[1, 0], [0, 0]]], dtype=torch.float)\n","\n","sparse_a = a.to_sparse()\n","sparse_b = b.to_sparse()\n","\n","print('2ì°¨ì› Sparse Tensor ì¸ë±ì‹±')\n","print(a[0] == sparse_a[0].to_dense())\n","\n","print('\\n')\n","\n","print('3ì°¨ì› Sprase Tensor ì¸ë±ì‹±')\n","print(b[0] == sparse_b[0].to_dense())"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":423,"status":"error","timestamp":1689151656029,"user":{"displayName":"Eddie(ê¹€ìœ¤ê¸°)","userId":"11850705511374304262"},"user_tz":-540},"id":"L6Ar7NX9oUkG","outputId":"eff7bdcc-0418-45ca-83ec-f8fd3cb4d395"},"outputs":[{"ename":"NotImplementedError","evalue":"Could not run 'aten::as_strided' with arguments from the 'SparseCPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::as_strided' is only available for these backends: [CPU, CUDA, Meta, QuantizedCPU, QuantizedCUDA, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMTIA, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradMeta, AutogradNestedTensor, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nCPU: registered at aten/src/ATen/RegisterCPU.cpp:31419 [kernel]\nCUDA: registered at aten/src/ATen/RegisterCUDA.cpp:44504 [kernel]\nMeta: registered at aten/src/ATen/RegisterMeta.cpp:26984 [kernel]\nQuantizedCPU: registered at aten/src/ATen/RegisterQuantizedCPU.cpp:951 [kernel]\nQuantizedCUDA: registered at aten/src/ATen/RegisterQuantizedCUDA.cpp:459 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:154 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:497 [backend fallback]\nFunctionalize: registered at aten/src/ATen/RegisterFunctionalization_0.cpp:22129 [kernel]\nNamed: fallthrough registered at ../aten/src/ATen/core/NamedRegistrations.cpp:11 [kernel]\nConjugate: fallthrough registered at ../aten/src/ATen/ConjugateFallback.cpp:21 [kernel]\nNegative: fallthrough registered at ../aten/src/ATen/native/NegateFallback.cpp:22 [kernel]\nZeroTensor: registered at aten/src/ATen/RegisterZeroTensor.cpp:161 [kernel]\nADInplaceOrView: registered at ../torch/csrc/autograd/generated/ADInplaceOrViewType_0.cpp:4930 [kernel]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17438 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17438 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17438 [autograd kernel]\nAutogradHIP: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17438 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17438 [autograd kernel]\nAutogradMPS: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17438 [autograd kernel]\nAutogradIPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17438 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17438 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17438 [autograd kernel]\nAutogradVE: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17438 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17438 [autograd kernel]\nAutogradMTIA: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17438 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17438 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17438 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17438 [autograd kernel]\nAutogradMeta: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17438 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17438 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_0.cpp:16910 [kernel]\nAutocastCPU: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:378 [backend fallback]\nAutocastCUDA: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:244 [backend fallback]\nFuncTorchBatched: registered at ../aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:735 [kernel]\nBatchedNestedTensor: registered at ../aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:758 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at ../aten/src/ATen/functorch/VmapModeRegistrations.cpp:27 [backend fallback]\nBatched: registered at ../aten/src/ATen/LegacyBatchingRegistrations.cpp:1079 [kernel]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at ../aten/src/ATen/functorch/TensorWrapper.cpp:202 [backend fallback]\nPythonTLSSnapshot: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:162 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:493 [backend fallback]\nPreDispatch: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:166 [backend fallback]\nPythonDispatcher: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:158 [backend fallback]\n","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m a \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m], [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\u001b[38;5;241m.\u001b[39mto_sparse_csr() \u001b[38;5;66;03m# 2dim Sparse Tensor (CSR)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43ma\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;66;03m# 0í–‰ì˜ ëª¨ë“  ì›ì†Œ ì¶”ì¶œ => ì—ëŸ¬ ë°œìƒ\u001b[39;00m\n","\u001b[0;31mNotImplementedError\u001b[0m: Could not run 'aten::as_strided' with arguments from the 'SparseCPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::as_strided' is only available for these backends: [CPU, CUDA, Meta, QuantizedCPU, QuantizedCUDA, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMTIA, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradMeta, AutogradNestedTensor, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nCPU: registered at aten/src/ATen/RegisterCPU.cpp:31419 [kernel]\nCUDA: registered at aten/src/ATen/RegisterCUDA.cpp:44504 [kernel]\nMeta: registered at aten/src/ATen/RegisterMeta.cpp:26984 [kernel]\nQuantizedCPU: registered at aten/src/ATen/RegisterQuantizedCPU.cpp:951 [kernel]\nQuantizedCUDA: registered at aten/src/ATen/RegisterQuantizedCUDA.cpp:459 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:154 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:497 [backend fallback]\nFunctionalize: registered at aten/src/ATen/RegisterFunctionalization_0.cpp:22129 [kernel]\nNamed: fallthrough registered at ../aten/src/ATen/core/NamedRegistrations.cpp:11 [kernel]\nConjugate: fallthrough registered at ../aten/src/ATen/ConjugateFallback.cpp:21 [kernel]\nNegative: fallthrough registered at ../aten/src/ATen/native/NegateFallback.cpp:22 [kernel]\nZeroTensor: registered at aten/src/ATen/RegisterZeroTensor.cpp:161 [kernel]\nADInplaceOrView: registered at ../torch/csrc/autograd/generated/ADInplaceOrViewType_0.cpp:4930 [kernel]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17438 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17438 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17438 [autograd kernel]\nAutogradHIP: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17438 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17438 [autograd kernel]\nAutogradMPS: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17438 [autograd kernel]\nAutogradIPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17438 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17438 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17438 [autograd kernel]\nAutogradVE: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17438 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17438 [autograd kernel]\nAutogradMTIA: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17438 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17438 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17438 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17438 [autograd kernel]\nAutogradMeta: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17438 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17438 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_0.cpp:16910 [kernel]\nAutocastCPU: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:378 [backend fallback]\nAutocastCUDA: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:244 [backend fallback]\nFuncTorchBatched: registered at ../aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:735 [kernel]\nBatchedNestedTensor: registered at ../aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:758 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at ../aten/src/ATen/functorch/VmapModeRegistrations.cpp:27 [backend fallback]\nBatched: registered at ../aten/src/ATen/LegacyBatchingRegistrations.cpp:1079 [kernel]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at ../aten/src/ATen/functorch/TensorWrapper.cpp:202 [backend fallback]\nPythonTLSSnapshot: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:162 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:493 [backend fallback]\nPreDispatch: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:166 [backend fallback]\nPythonDispatcher: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:158 [backend fallback]\n"]}],"source":["a = torch.tensor([[0, 1], [0, 2]], dtype=torch.float).to_sparse_csr() # 2dim Sparse Tensor (CSR)\n","a[0,:] # 0í–‰ì˜ ëª¨ë“  ì›ì†Œ ì¶”ì¶œ => ì—ëŸ¬ ë°œìƒ"]},{"cell_type":"markdown","metadata":{"id":"lSVO_LtU2erF"},"source":["#Reference\n","> <b><font color = green>(ğŸ“’ê°€ì´ë“œ)\n","- <a href='https://pytorch.org/docs/stable/index.html'>PyTorch ê³µì‹ ë¬¸ì„œ</a>\n","- <a href='https://bkshin.tistory.com/entry/NLP-7-%ED%9D%AC%EC%86%8C-%ED%96%89%EB%A0%AC-Sparse-Matrix-COO-%ED%98%95%EC%8B%9D-CSR-%ED%98%95%EC%8B%9D'>COO ì™€ CSR/CSC</a>"]},{"cell_type":"markdown","metadata":{"id":"4by_4X6tvaX6"},"source":["## Required Package\n","\n","> torch == 2.0.1"]},{"cell_type":"markdown","metadata":{"id":"-P3G5QSQvbSg"},"source":["## ì½˜í…ì¸  ë¼ì´ì„ ìŠ¤\n","\n","ì €ì‘ê¶Œ : <font color='blue'> <b> Â©2023 by Upstage X fastcampus Co., Ltd. All rights reserved.</font></b>\n","\n","<font color='red'><b>WARNING</font> : ë³¸ êµìœ¡ ì½˜í…ì¸ ì˜ ì§€ì‹ì¬ì‚°ê¶Œì€ ì—…ìŠ¤í…Œì´ì§€ ë° íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤ì— ê·€ì†ë©ë‹ˆë‹¤. ë³¸ ì½˜í…ì¸ ë¥¼ ì–´ë– í•œ ê²½ë¡œë¡œë“  ì™¸ë¶€ë¡œ ìœ ì¶œ ë° ìˆ˜ì •í•˜ëŠ” í–‰ìœ„ë¥¼ ì—„ê²©íˆ ê¸ˆí•©ë‹ˆë‹¤. </b>"]}],"metadata":{"colab":{"gpuType":"T4","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
